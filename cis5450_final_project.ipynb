{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyIE7oUBHsoY"
      },
      "source": [
        "# **CIS 5450 Final Project - Climate Change Analysis**\n",
        "*Wendy Deng, Anna Zhou, Kaily Liu*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seVvVpxCHsob"
      },
      "source": [
        "# Part 1: Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyLPzkKsHsoc"
      },
      "source": [
        "Climate change is one of the most urgent issues of our time and its impacts on our planet are becoming increasingly severe. Our project focuses on analyzing and predicting global temperatures to better understand how climate change is influencing our world.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaSOo5riHsoc"
      },
      "source": [
        "# Part 2: Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbKJlr_eHsoc"
      },
      "source": [
        "This script sets up an environment for data analysis, visualization, time series analysis, and machine learning model building.\n",
        "\n",
        "It begins by installing and importing necessary libraries for data manipulation, visualization, statistical analysis, and machine learning.\n",
        "\n",
        "The visualization section includes modules for 3D plotting, Matplotlib, Seaborn, Cartopy, and Plotly.\n",
        "\n",
        "The statistical tools section includes modules for time series analysis, such as ARIMA models, ADF test, and autocorrelation/partial autocorrelation plots.\n",
        "\n",
        "The machine learning model building section imports modules from scikit-learn for preprocessing, splitting data, linear regression modeling, and evaluation metrics.\n",
        "\n",
        "Additionally, there's a section for printing file paths in the '/kaggle/input' directory, to show what Kaggle datasets we are working with.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBd2CgALHsoc"
      },
      "outputs": [],
      "source": [
        "# installing the Cartopy library using pip\n",
        "!pip install cartopy\n",
        "!pip install fuzzywuzzy\n",
        "!pip install sqlalchemy==1.4.46\n",
        "!pip install pandasql\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install pmdarima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RqMop-BHsoe"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandasql as ps\n",
        "from datetime import date\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# importing visualization tools\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import plotly.graph_objects as go\n",
        "import plotly.tools as tls\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "py.init_notebook_mode(connected=True)\n",
        "pio.renderers.default = \"colab\"\n",
        "\n",
        "# importing other dynamic visualization tools\n",
        "import urllib.request\n",
        "import json\n",
        "import geopandas as gpd\n",
        "from fuzzywuzzy import process\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "# importing statistical tools\n",
        "import itertools\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from pmdarima.arima import auto_arima\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# importing necessary modules for machine learning model building\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# importing more necessary tools for modeling\n",
        "from scipy.stats import pearsonr\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from prophet import Prophet\n",
        "\n",
        "# when using Kaggle notebooks, printing the file paths in the input directory\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2pFGcqWHsoe"
      },
      "source": [
        "## 2.1 Loading & Preprocessing Global Temperatures Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AR4GCRiJIj9"
      },
      "source": [
        "This section of the notebook explores the Kaggle GlobalTemperatures.csv file (Global Land and Ocean-and-Land Temperatures). It includes information on:\n",
        "\n",
        "- Date: Starting from 1750 for average land temperature and 1850 for maximum and minimum land temperatures, as well as global ocean and land temperatures.\n",
        "- LandAverageTemperature: Represents the global average land temperature in degrees Celsius.\n",
        "- LandAverageTemperatureUncertainty: Indicates the 95% confidence interval around the average land temperature.\n",
        "- LandMaxTemperature: Denotes the global average maximum land temperature in degrees Celsius.\n",
        "- LandMaxTemperatureUncertainty: Represents the 95% confidence interval around the maximum land temperature.\n",
        "- LandMinTemperature: Specifies the global average minimum land temperature in degrees Celsius.\n",
        "- LandMinTemperatureUncertainty: Depicts the 95% confidence interval around the minimum land temperature.\n",
        "- LandAndOceanAverageTemperature: Signifies the global average land and ocean temperature in degrees Celsius.\n",
        "- LandAndOceanAverageTemperatureUncertainty: Represents the 95% confidence interval around the global average land and ocean temperature.\n",
        "\n",
        "We load the dataset into our notebook, and check that all cells are correct and present. Then, we clean the dataset:\n",
        "- We convert the dt column into DateTime objects.\n",
        "- We divide the dataset into two dataframes: `global_temp_land` and `global_temp_land_and_ocean` to handle disparities in the data, and clean them in `global_temp_land_cleaned` and `global_temp_land_and_ocean_cleaned`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYM1X0oVHsoe"
      },
      "source": [
        "### 2.1.1 Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciU9qQdHHsof"
      },
      "outputs": [],
      "source": [
        "# reading in the csv file\n",
        "global_temp = pd.read_csv('/content/drive/MyDrive/CIS545/CIS545 Final Project/data/GlobalTemperatures.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40rR3Ju1Hsof"
      },
      "source": [
        "### 2.1.2 Analyzing Data Structure & Subsetting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JIfbMRvHsof"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM global_temp\n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query using pandasql\n",
        "global_temp_head = ps.sqldf(query, locals())\n",
        "\n",
        "# Convert to a pandas DataFrame\n",
        "global_temp_head = pd.DataFrame(global_temp_head)\n",
        "\n",
        "global_temp_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjNImm8nHsof"
      },
      "outputs": [],
      "source": [
        "# getting the latest data, to check that it was properly imported, and contains specified information\n",
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM global_temp\n",
        "ORDER BY ROWID DESC\n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query using pandasql\n",
        "global_temp_tail = ps.sqldf(query, locals())\n",
        "\n",
        "# Convert to a pandas DataFrame\n",
        "global_temp_tail = pd.DataFrame(global_temp_tail)\n",
        "\n",
        "global_temp_tail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mtnxOfXHsof"
      },
      "source": [
        "As we can see from the dt, our data documents temperature in land and ocean from 1750 to 2015, incrementing monthly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VzI8C2LHsof"
      },
      "outputs": [],
      "source": [
        "# checking that the file was properly imported and contains correct data\n",
        "global_temp.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cFM0d2GHsof"
      },
      "source": [
        "The column 'dt' is currrently of type object, we would want to convert that to type datetime for easier analysis, as well as adding another column for year for separating the data into subsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA9ZTHEwHsof"
      },
      "outputs": [],
      "source": [
        "#convert dt to a datetime object\n",
        "global_temp['dt'] = pd.to_datetime(global_temp['dt'])\n",
        "\n",
        "#add a column for year\n",
        "global_temp[\"year\"] = global_temp['dt'].dt.year.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDeeFU57Hsof"
      },
      "outputs": [],
      "source": [
        "# get a summary of the central tendency, dispersion, and shape of the distribution of the numerical columns in the dataframe\n",
        "global_temp.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPVq2XXPHsof"
      },
      "source": [
        "Since land temperature starts in 1750 and max, min, and ocean temperature start in 1850, we will analyze the land and ocean temperatures separately. We will create two dataframes: one for land average temperature,  one for land and ocean temperatures after 1850."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvLxHwmGHsof"
      },
      "outputs": [],
      "source": [
        "# creating the gloabl_temp_land dataframe\n",
        "global_temp_land = global_temp[['dt', 'LandAverageTemperature', 'LandAverageTemperatureUncertainty', 'year']].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xsl1FR0Hsog"
      },
      "outputs": [],
      "source": [
        "# creating the global_temp_land_and_ocean dataframe\n",
        "global_temp_land_and_ocean = global_temp[global_temp['dt'].dt.year > 1850]\n",
        "\n",
        "columns = [\n",
        "    'dt',\n",
        "    'LandMaxTemperature',\n",
        "    'LandMaxTemperatureUncertainty',\n",
        "    'LandMinTemperature',\n",
        "    'LandMinTemperatureUncertainty',\n",
        "    'LandAndOceanAverageTemperature',\n",
        "    'LandAndOceanAverageTemperatureUncertainty'\n",
        "]\n",
        "\n",
        "global_temp_land_and_ocean = global_temp_land_and_ocean[columns].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaXjm2hWHsog"
      },
      "source": [
        "### 2.1.3 Analyzing Land Temperatures Data & Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOYmHY3gHsog"
      },
      "outputs": [],
      "source": [
        "# from the info on the dataframe, we see that there are some null values, which we need to clean\n",
        "global_temp_land.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2ZK57JfHsog"
      },
      "outputs": [],
      "source": [
        "# getting summary statistics of the central tendency, dispersion, and shape of the distribution of the global_temp_land data\n",
        "global_temp_land.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh9aI3nKHsog"
      },
      "source": [
        "We will take a look at the rows with nulls to decide whether to drop them or to impute the missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dIjkH8PHsog"
      },
      "outputs": [],
      "source": [
        "# creating a new dataframe that contains only the rows with null values from the original dataframe\n",
        "global_temp_land_null = global_temp_land[global_temp_land.isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3nKHLhiHsog"
      },
      "outputs": [],
      "source": [
        "# getting summary of the dataframe, including the data types of each column and the number of non-null values\n",
        "global_temp_land_null.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JL2bbmRWHsog"
      },
      "outputs": [],
      "source": [
        "# getting summary statistics of the central tendency, dispersion, and shape of the distribution of the global_temp_land_null data\n",
        "# we use this to isolate what data is missing, and determine if it can be dropped\n",
        "global_temp_land_null.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDOd8VnWHsog"
      },
      "source": [
        "There are only 12 rows that have missing values in 'LandAverageTemperature' and 'LandAverageTemperatureUncertainty', which is $12/3193 = 0.00376$ of the data and they are all within the years 1750 to 1752, which are the first three years in which this data is collected. Since it is likely that these data got lost due to how early they were collected and they only constitute $0.376$% of the data, we decided to drop these rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RISq0X5RO9nu"
      },
      "outputs": [],
      "source": [
        "global_temp_land_cleaned = global_temp_land.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSp72UUkHsog"
      },
      "source": [
        "### 2.1.4 Analyzing Land and Ocean Data & Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEJujsorHsoh"
      },
      "outputs": [],
      "source": [
        "# from the info on the dataframe, we see that there are some null values, which we need to clean\n",
        "global_temp_land_and_ocean.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQDXlsAKHsoh"
      },
      "outputs": [],
      "source": [
        "# getting summary statistics of the central tendency, dispersion, and shape of the distribution of the global_temp_land_and_ocean data\n",
        "global_temp_land_and_ocean.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJpRp7NCHsoh"
      },
      "source": [
        "There are no nulls, we can proceed with loading other datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNF6HgpYHsoh"
      },
      "outputs": [],
      "source": [
        "# creating a copy of global_temp_land_and_ocean to be global_temp_land_and_ocean_cleaned because there are no null values, and we want to keep varaible names uniform\n",
        "global_temp_land_and_ocean_cleaned = global_temp_land_and_ocean.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXBBdvRLHsoh"
      },
      "source": [
        "## 2.2 Loading & Preprocessing Global Temperatures by State Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOl10PkKQBp9"
      },
      "source": [
        "This section of the notebook explores the Kaggle GlobalLandTemperaturesByState.csv file (Global Average Land Temperature by State). It includes information on:\n",
        "\n",
        "- Date (dt): Starting from 1855 to 2013.\n",
        "- AverageTemperature: Represents the average land temperature in degrees Celsius.\n",
        "- AverageTemperatureUncertainty: Indicates the 95% confidence interval around the average temperature.\n",
        "- State: State that the temperature represents.\n",
        "- Country: Country the state belongs to.\n",
        "\n",
        "We load the dataset into our notebook, and check that all cells are correct and present. Then, we clean the dataset:\n",
        "- We convert the dt column into DateTime objects.\n",
        "- We analyze the missing temperature data based on date and country."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxnbxkAAHsoh"
      },
      "source": [
        "### 2.2.1 Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V9lr6PjHsoh"
      },
      "outputs": [],
      "source": [
        "# reading in the csv file\n",
        "global_temp_state = pd.read_csv('/content/drive/MyDrive/CIS545/CIS545 Final Project/data/GlobalLandTemperaturesByState.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7knB_F33Hsol"
      },
      "source": [
        "### 2.2.2 Analyzing Data Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU56ohCFHsol"
      },
      "outputs": [],
      "source": [
        "# getting the earliest data, to check that it was properly imported, and contains specified information\n",
        "global_temp_state.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxBmBpJlHsol"
      },
      "outputs": [],
      "source": [
        "# getting the latest data, to check that it was properly imported, and contains specified information\n",
        "global_temp_state.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-us-WPWyHsol"
      },
      "outputs": [],
      "source": [
        "# checking that the file was properly imported and contains correct data\n",
        "global_temp_state.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqSz62cnHsol"
      },
      "outputs": [],
      "source": [
        "# convert 'dt' to datetime\n",
        "global_temp_state['dt'] = pd.to_datetime(global_temp_state['dt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GniuV6SfHsol"
      },
      "outputs": [],
      "source": [
        "# get a summary of the central tendency, dispersion, and shape of the distribution of the numerical columns in the dataframe\n",
        "global_temp_state.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbcQR2fWHsom"
      },
      "outputs": [],
      "source": [
        "# calculating the number of unique states present in the 'State' column\n",
        "len(global_temp_state['State'].unique().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB8P7X-FjLyQ"
      },
      "outputs": [],
      "source": [
        "# determining the unique states present in the 'Country' column\n",
        "global_temp_state['Country'].unique().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZDhqYoCHsom"
      },
      "outputs": [],
      "source": [
        "# calculating the number of unique states present in the 'Country' column\n",
        "len(global_temp_state['Country'].unique().tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO7ZjZbRHsom"
      },
      "source": [
        "After loading this data, and analyzing it, we discovered that this dataset presents information on the global temperatures for 7 countries and a total of 241 states within these countries.\n",
        "\n",
        "These countries are:\n",
        "- Brazil\n",
        "- Russia\n",
        "- United States\n",
        "- China\n",
        "- India\n",
        "- Canada\n",
        "- Australia\n",
        "\n",
        "While this data isn't comprehensive for representing the entire world, it provides us with temperature information for countries that span the world."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZCEwjuIHsom"
      },
      "source": [
        "### 2.2.3 Analyzing Data & Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTDE4xJYHsom"
      },
      "outputs": [],
      "source": [
        "# getting all rows that have null values\n",
        "global_temp_state_null = global_temp_state[global_temp_state.isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9_-QiSoHson"
      },
      "outputs": [],
      "source": [
        "# getting a concise summary of the global_temp_state_null dataframe, to see what values are null\n",
        "global_temp_state_null.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19YwywX6Hson"
      },
      "outputs": [],
      "source": [
        "# getting summary statistics of the data to better understand what data these rows hold\n",
        "global_temp_state_null.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFmTerihHson"
      },
      "source": [
        "We will plot the 'dt' column of the missing values on a histogram to see if there are any patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxKCnFEXHson"
      },
      "outputs": [],
      "source": [
        "# plotting histogram of dates with missing temperatures using matplotlib\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(global_temp_state_null['dt'], bins=50, edgecolor='black')\n",
        "plt.title('Figure 2.2.3a: Histogram of Dates with Missing Temperature Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd69WB0DHson"
      },
      "source": [
        "There are 25648 rows with missing values within 645675 rows ($3.97$% of total data), and according to Figure 2.2.3a, these rows are concentrated in the earlier time periods. Because these rows consist of a small part of our dataset, we will drop them for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94e3fmzZHson"
      },
      "source": [
        "Do the same with 'State' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDV6GQVuHson"
      },
      "outputs": [],
      "source": [
        "# plotting histogram of states with missing temperatures using matplotlib\n",
        "plt.figure(figsize=(50, 20))\n",
        "plt.hist(global_temp_state_null['State'], bins=50, edgecolor='black')\n",
        "plt.title('Figure 2.2.3b: Histogram of States with Missing Temperature Data')\n",
        "plt.xlabel('State')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv4v4eVoHson"
      },
      "source": [
        "There are also 25648 rows with missing values within 645675 rows ($3.97$% of total data). As depicted in Figure 2.2.3b, these rows encompass cities worldwide. We will drop them because they take up such a small percentage of our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-NiRacmHson"
      },
      "source": [
        "Do the same with 'Country' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLlMErnGHson"
      },
      "outputs": [],
      "source": [
        "# plotting histogram of countries with missing temperatures using matplotlib\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(global_temp_state_null['Country'], bins=50, edgecolor='black')\n",
        "plt.title('Figure 2.2.3c: Histogram of Countries with Missing Temperature Data')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf7WkJPLHson"
      },
      "source": [
        "This figure shows that the missing data is relatively evenly distributed between all countries, so we can drop it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db8KzHJsrTpw"
      },
      "outputs": [],
      "source": [
        "global_temp_state_cleaned = global_temp_state.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns103RvQHson"
      },
      "source": [
        "## 2.3 Loading & Preprocessing Global Temperatures by Country Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSWXwoKvggnO"
      },
      "source": [
        "This section of the notebook explores the Kaggle GlobalLandTemperaturesByCountry.csv file (Global Average Land Temperature by State). It includes information on:\n",
        "\n",
        "- Date (dt): Starting from 1855 to 2013.\n",
        "- AverageTemperature: Represents the average land temperature in degrees Celsius.\n",
        "- AverageTemperatureUncertainty: Indicates the 95% confidence interval around the average temperature.\n",
        "- Country: Country the temperature was collected in.\n",
        "\n",
        "We load the dataset into our notebook, and check that all cells are correct and present. Then, we clean the dataset:\n",
        "- We convert the dt column into DateTime objects.\n",
        "- We analyze the missing temperature data based on date and country."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTPWzcsHHson"
      },
      "source": [
        "### 2.3.1 Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG68naFsHson"
      },
      "outputs": [],
      "source": [
        "# reading in the csv file\n",
        "global_temp_country = pd.read_csv('/content/drive/MyDrive/CIS545/CIS545 Final Project/data/GlobalLandTemperaturesByCountry.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC1XKBBEHson"
      },
      "source": [
        "### 2.3.2 Analyzing Data Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x7CGflDHsoo"
      },
      "outputs": [],
      "source": [
        "# getting the earliest data, to check that it was properly imported, and contains specified information\n",
        "global_temp_country.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjNVgQtRHsoo"
      },
      "outputs": [],
      "source": [
        "# getting the latest data, to check that it was properly imported, and contains specified information\n",
        "global_temp_country.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpebQBnOHsoo"
      },
      "outputs": [],
      "source": [
        "# checking that the file was properly imported and contains correct data\n",
        "global_temp_country.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8vle9HmHsoo"
      },
      "outputs": [],
      "source": [
        "# convert 'dt' to datetime\n",
        "global_temp_country['dt'] = pd.to_datetime(global_temp_country['dt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxJQjcKBHsoo"
      },
      "outputs": [],
      "source": [
        "# get a summary of the central tendency, dispersion, and shape of the distribution of the numerical columns in the dataframe\n",
        "global_temp_country.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXERYnXiHsoo"
      },
      "outputs": [],
      "source": [
        "# calculating the number of unique countries present in the 'Country' column\n",
        "len(global_temp_country['Country'].unique().tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNA6LaNkHsoo"
      },
      "source": [
        "After loading this data, and analyzing it, we discovered that this dataset presents information on the global temperatures for 243 countries.\n",
        "\n",
        "This data is comprehensive for representing the entire world. The UN recognizes 251 counties and territories, which is close to the 243 that are represented in this dataset. However, something we noticed during EDA is that continents are considered countries in this dataset, so we will remove them in the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVCzq-POavNF"
      },
      "outputs": [],
      "source": [
        "continents = ['Asia', 'Europe', 'Africa', 'North America', 'South America', 'Oceania', 'Antarctica']\n",
        "\n",
        "global_temp_country = global_temp_country[~global_temp_country['Country'].isin(continents)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbmSOn_sHsoo"
      },
      "source": [
        "### 2.3.3 Analyzing Data & Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ykw5qTpGHsoo"
      },
      "outputs": [],
      "source": [
        "global_temp_country_null = global_temp_country[global_temp_country.isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfMP2vGfHsoo"
      },
      "outputs": [],
      "source": [
        "global_temp_country_null.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8wi3islHsoo"
      },
      "outputs": [],
      "source": [
        "global_temp_country_null.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u3broEQHsoo"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(global_temp_country_null['dt'], bins=50, edgecolor='black')\n",
        "plt.title('Figure 2.2.3: Histogram of Dates with Missing Temperature Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ecI_bo6Hsoo"
      },
      "source": [
        "There are 32651 rows with missing values within 577462 rows ($5.65$% of total data). Like before, the null values make up an insignificant percentage of our dataset, so we will drop it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9PyT96xHsoo"
      },
      "source": [
        "Do the same with 'Country' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZAD03ZLHsoo"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(50, 20))\n",
        "plt.hist(global_temp_country_null['Country'], bins=50, edgecolor='black')\n",
        "plt.title('Figure 2.2.3: Histogram of Countries with Missing Temperature Data')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpUVQOGOHsop"
      },
      "source": [
        "There are 32651 rows with missing values within 577462 rows ($5.65$% of total data). Since these countries are spread throughout the world, we can drop the null values in our cleaned data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBWjvxHOroOK"
      },
      "outputs": [],
      "source": [
        "global_temp_country_cleaned = global_temp_country.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVdekms5Hsop"
      },
      "source": [
        "## 2.4 Loading & Preprocessing Global Temperatures by City Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADtqopDTlzu1"
      },
      "source": [
        "This section of the notebook explores the Kaggle GlobalLandTemperaturesByCity.csv file (Global Land Temperatures by City). It includes information on:\n",
        "\n",
        "- Date (dt): Starting from 1743 to 2013.\n",
        "- AverageTemperature: Represents the average land temperature in degrees Celsius.\n",
        "- AverageTemperatureUncertainty: Indicates the 95% confidence interval around the average temperature.\n",
        "- City: City that the temperature represents.\n",
        "- Country: Country the city belongs to.\n",
        "- Latitude: Latitudinal coordinates for the city.\n",
        "- Longitude: Longitudinal coordinates for the city.\n",
        "\n",
        "We load the dataset into our notebook, and check that all cells are correct and present. Then, we clean the dataset:\n",
        "- We convert the dt column into DateTime objects.\n",
        "- We analyze the missing temperature data based on date and country."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPK9b2PPHsop"
      },
      "source": [
        "### 2.4.1 Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2EPrE3LHsop"
      },
      "outputs": [],
      "source": [
        "# reading in the csv file\n",
        "global_temp_city = pd.read_csv('/content/drive/MyDrive/CIS545/CIS545 Final Project/data/GlobalLandTemperaturesByCity.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eQhUpI7Hsop"
      },
      "source": [
        "### 2.4.2 Analyzing Data Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-Q1K1zbHsop"
      },
      "outputs": [],
      "source": [
        "# getting the earliest data, to check that it was properly imported, and contains specified information\n",
        "global_temp_city.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJf2CokYHsop"
      },
      "outputs": [],
      "source": [
        "# getting the latest data, to check that it was properly imported, and contains specified information\n",
        "global_temp_city.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZC8lhiqHsop"
      },
      "outputs": [],
      "source": [
        "# checking that the file was properly imported and contains correct data\n",
        "global_temp_city.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DQvvhYRHsop"
      },
      "outputs": [],
      "source": [
        "# convert dt to a datetime object\n",
        "global_temp_city['dt'] = pd.to_datetime(global_temp_city['dt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjaX-m7gHsop"
      },
      "outputs": [],
      "source": [
        "# get a summary of the central tendency, dispersion, and shape of the distribution of the numerical columns in the dataframe\n",
        "global_temp_city.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp9EFgROHsop"
      },
      "outputs": [],
      "source": [
        "# determining the number of unique cities in our dataset\n",
        "len(global_temp_city['City'].unique().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lQt2RsRHsop"
      },
      "outputs": [],
      "source": [
        "# determining the number of unique countries in our dataset\n",
        "len(global_temp_city['Country'].unique().tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuO5YiZfnvDG"
      },
      "source": [
        "From the above analysis, we know that our dataset spans 3,448 cities in 159 countries. This is an extremely comprehensize dataset, which spans countries around the globe, and can be used to analyze temperature change for these cities and the countries these cities lie in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Al8aAM8Hsop"
      },
      "source": [
        "### 2.4.3 Analyzing Data & Handling Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdbquTJjHsop"
      },
      "source": [
        "Since Latitude and Longtitude are of type object due to their ending letters, we will drop them and convert both columns to type float with signs for easier visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-IzaWC-Hsop"
      },
      "outputs": [],
      "source": [
        "#drop the ending letter in Latitude and Longitude\n",
        "global_temp_city['Latitude'] = np.where(global_temp_city['Latitude'].str.contains('S'),\n",
        "                                        '-' + global_temp_city['Latitude'],\n",
        "                                        global_temp_city['Latitude'])\n",
        "global_temp_city['Longitude'] = np.where(global_temp_city['Longitude'].str.contains('W'),\n",
        "                                         '-' + global_temp_city['Longitude'],\n",
        "                                         global_temp_city['Longitude'])\n",
        "\n",
        "#convert Latitude and Longtitude to type float\n",
        "global_temp_city['Latitude'] = global_temp_city['Latitude'].str.replace('N', '').str.replace('S', '').astype(float)\n",
        "global_temp_city['Longitude'] = global_temp_city['Longitude'].str.replace('E', '').str.replace('W', '').astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faeOocZKHsop"
      },
      "source": [
        "Take a look at the nulls and their distribution before deciding to drop them or impute them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQEPOz_SHsoq"
      },
      "outputs": [],
      "source": [
        "# creating a new dataframe that contains only the null rows from the original dataframe\n",
        "global_temp_city_null = global_temp_city[global_temp_city.isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE3JaSWTHsoq"
      },
      "outputs": [],
      "source": [
        "# getting summary of the dataframe, including the data types of each column and the number of non-null values\n",
        "global_temp_city_null.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJeloaicHsoq"
      },
      "outputs": [],
      "source": [
        "# plotting histogram of dates with missing temperatures using matplotlib\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(global_temp_city_null['dt'], bins=50, edgecolor='black')\n",
        "plt.title('Figure 2.4.3: Histogram of Dates with Missing Temperature Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ZHb_9OHsoq"
      },
      "source": [
        "Like in the other datasets, the rows with missing temperature data are concentrated in the earlier time periods. Specifically, 364130 out of 8599212 rows contain a null temperature value (4.23%). Dropping these rows still maintains the majority of our dataset, so we will remove them from our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvdL63woLYeF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(50, 20))\n",
        "selected_cities = np.random.choice(global_temp_city_null['City'], size=150, replace=False)\n",
        "plt.hist(selected_cities, bins=150, edgecolor='black')\n",
        "plt.title('Figure 2.2.3: Histogram of Cities with Missing Temperature Data')\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOZ846t1MJ2T"
      },
      "source": [
        "Since the null values account for 4.23% of our dataset, we will drop them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shMvLaWxr8U6"
      },
      "outputs": [],
      "source": [
        "global_temp_city_cleaned = global_temp_city.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgD86QrKHsoq"
      },
      "source": [
        "## 2.5 Loading & Preprocessing Global Temperatures by Major City Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6QloYTBpBMS"
      },
      "source": [
        "This section of the notebook explores the Kaggle GlobalTemperaturesByMajorCity.csv file (Global Average Land Temperature by Major City). It includes information on:\n",
        "\n",
        "- Date (dt): Starting from 1855 to 2013.\n",
        "- AverageTemperature: Represents the average land temperature in degrees Celsius.\n",
        "- AverageTemperatureUncertainty: Indicates the 95% confidence interval around the average temperature.\n",
        "- City: City that the temperature represents.\n",
        "- Country: Country the city belongs to.\n",
        "- Latitude: Latitudinal coordinate of the city\n",
        "- Longitude: Longitudinal coordinate of the city\n",
        "\n",
        "We load the dataset into our notebook, and check that all cells are correct and present. Then, we clean the dataset:\n",
        "- We convert the dt column into DateTime objects.\n",
        "- We analyze the missing temperature data based on date and city."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Nsh-hO0Hsoq"
      },
      "source": [
        "### 2.5.1 Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJCCxMWiHsoq"
      },
      "outputs": [],
      "source": [
        "# reading in the csv file\n",
        "global_temp_major_city = pd.read_csv('/content/drive/MyDrive/CIS545/CIS545 Final Project/data/GlobalLandTemperaturesByMajorCity.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndd02dS3Hsoq"
      },
      "source": [
        "### 2.5.2 Analyzing Data Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeLWXVMTHsoq"
      },
      "outputs": [],
      "source": [
        "# getting the earliest data, to check that it was properly imported, and contains specified information\n",
        "global_temp_major_city.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNUhlPXFHsoq"
      },
      "outputs": [],
      "source": [
        "# getting the latest data, to check that it was properly imported, and contains specified information\n",
        "global_temp_major_city.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Whdrz0qoHsos"
      },
      "outputs": [],
      "source": [
        "# checking that the file was properly imported and contains correct data\n",
        "global_temp_major_city.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYzl0McTHsos"
      },
      "outputs": [],
      "source": [
        "# convert 'dt' to datetime\n",
        "global_temp_major_city['dt'] = pd.to_datetime(global_temp_major_city['dt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWH9M17AHsos"
      },
      "outputs": [],
      "source": [
        "# get a summary of the central tendency, dispersion, and shape of the distribution of the numerical columns in the dataframe\n",
        "global_temp_major_city.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww7sRBNBHsos"
      },
      "outputs": [],
      "source": [
        "# calculating the number of unique cities present in the 'City' column\n",
        "len(global_temp_major_city['City'].unique().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1WKx_uOHsos"
      },
      "outputs": [],
      "source": [
        "# calculating the number of unique cities present in the 'Country' column\n",
        "len(global_temp_major_city['Country'].unique().tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGambelwps-G"
      },
      "source": [
        "After loading this data and analyzing it, we discovered that this dataset presents information on the global temperatures for 100 cities in 49 countries.\n",
        "\n",
        "While this data isn't as comprehensive as the Cities or Countries file for representing the entire world, it provides us with temperature information for major cities, which can be used to determine how temperature changes will affect areas with higher populations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCO-qKTVHsot"
      },
      "source": [
        "### 2.5.3 Analyzing Data & Handling Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMshriT8Hsot"
      },
      "source": [
        "Same as the Global Temperatures by City data above, we will convert Latitude and Longtitude to type float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7E1CHuJHsot"
      },
      "outputs": [],
      "source": [
        "#drop the ending letter in Latitude and Longitude\n",
        "global_temp_major_city['Latitude'] = np.where(global_temp_major_city['Latitude'].str.contains('S'),\n",
        "                                        '-' + global_temp_major_city['Latitude'],\n",
        "                                        global_temp_major_city['Latitude'])\n",
        "global_temp_major_city['Longitude'] = np.where(global_temp_major_city['Longitude'].str.contains('W'),\n",
        "                                         '-' + global_temp_major_city['Longitude'],\n",
        "                                         global_temp_major_city['Longitude'])\n",
        "\n",
        "#convert Latitude and Longtitude to type float\n",
        "global_temp_major_city['Latitude'] = global_temp_major_city['Latitude'].str.replace('N', '').str.replace('S', '').astype(float)\n",
        "global_temp_major_city['Longitude'] = global_temp_major_city['Longitude'].str.replace('E', '').str.replace('W', '').astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51pGQV5BHsot"
      },
      "outputs": [],
      "source": [
        "# getting all rows that have null values\n",
        "global_temp_major_city_null = global_temp_major_city[global_temp_major_city.isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyzB5k6KHsot"
      },
      "outputs": [],
      "source": [
        "# getting a concise summary of the global_temp_state_null dataframe, to see what values are null\n",
        "global_temp_major_city_null.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sGGIr-hHsot"
      },
      "outputs": [],
      "source": [
        "# plotting histogram of dates with missing temperatures using matplotlib\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(global_temp_major_city_null['dt'], bins=50, edgecolor='black')\n",
        "plt.title('Figure 2.5.3: Histogram of Dates with Missing Temperature Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iYTQI4wHsot"
      },
      "source": [
        "The rows account for 4.60% of the dataset (11002 out of 239117 rows). We will drop them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt7X4eKpNNvg"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(50, 20))\n",
        "plt.hist(global_temp_major_city_null['City'], bins=50, edgecolor='black')\n",
        "plt.title('Figure 2.2.3: Histogram of Major Cities with Missing Temperature Data')\n",
        "plt.xlabel('Major City')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cev30hsoOOOS"
      },
      "source": [
        "Similar to the previous datasets, the major cities that have missing temperature data are distributed around the world, and take up an insignificant fraction of our dataset. We will drop them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vx4kXfCtsPbS"
      },
      "outputs": [],
      "source": [
        "global_temp_major_city_cleaned = global_temp_major_city.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUeHqe3csBrn"
      },
      "source": [
        "## 2.6 Copying Dataframes for Modeling\n",
        "\n",
        "We will make copies of the global_temp_land_cleaned, global_temp_land_and_ocean_cleaned, and global_temp_city_cleaned dataframes for modelling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1fcJY5rsd76"
      },
      "outputs": [],
      "source": [
        "global_temp_land_cleaned_modeling = global_temp_land_cleaned.copy()\n",
        "global_temp_land_and_ocean_cleaned_modeling = global_temp_land_and_ocean_cleaned.copy()\n",
        "global_temp_city_cleaned_modeling = global_temp_city_cleaned.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm_zWDWAHsou"
      },
      "source": [
        "# Part 3: Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbNmu2JpHsou"
      },
      "source": [
        "## 3.1 EDA in Global Land Temperatures Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lZmmKwet4NX"
      },
      "source": [
        "The following section conducts exploratory data analysis on the Global Land Temperatures Data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l56hNnctHsou"
      },
      "source": [
        "### 3.1.1 Visualize Trends in Land Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLHJra6jrjrr"
      },
      "source": [
        "The type of plot being created in this code is a line plot. It is used to visualize the trend in land average temperature over time. The plot includes two lines:\n",
        "\n",
        "- Monthly Average Temperature: This line represents the monthly average land temperature over time. It is drawn with some transparency (alpha=0.5) to show individual data points.\n",
        "\n",
        "- 10-Year Rolling Average: This line represents the 10-year rolling average of the land temperature. It is calculated to smooth out short-term fluctuations and highlight long-term trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxomPmgGHsou"
      },
      "outputs": [],
      "source": [
        "#calculate 10_year_rolling_avg\n",
        "global_temp_land_cleaned['10_year_rolling_avg'] = global_temp_land_cleaned['LandAverageTemperature'].rolling(window=120).mean()\n",
        "\n",
        "# Plot monthly average temperature and 10-year rolling average\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(global_temp_land_cleaned['dt'], global_temp_land_cleaned['LandAverageTemperature'], label='Monthly Average Temperature', alpha=0.5)\n",
        "plt.plot(global_temp_land_cleaned['dt'], global_temp_land_cleaned['10_year_rolling_avg'], label='10-Year Rolling Average', color='red', linewidth=2)\n",
        "plt.title('Land Average Temperature Over Time with 10 Years Rolling Average')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature (C)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSPJ6g0BHsov"
      },
      "source": [
        "We don't observe that much pattern; there is a slight upward trend, but not obvious enough to be significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAzVsFuvHsov"
      },
      "source": [
        "### 3.1.2 Interactive Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB45-50or_EB"
      },
      "source": [
        "This code creates an interactive Plotly line plot to illustrate the average land temperature and its uncertainty over the years. It first calculates the mean temperature and uncertainty for each year, then utilizes Plotly to generate a plot with two traces representing upper and lower uncertainty bounds, along with a trace for average temperature. The resulting interactive plot allows for a dynamic exploration of temperature trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yk6KCpeHsov"
      },
      "outputs": [],
      "source": [
        "# Extract the year from a date\n",
        "global_temp_land_cleaned['dt'] = pd.to_datetime(global_temp_land_cleaned['dt'])\n",
        "years = np.unique(global_temp_land_cleaned['dt'].dt.year)\n",
        "mean_temp_world = []\n",
        "mean_temp_world_uncertainty = []\n",
        "\n",
        "# Calculate mean temperature and uncertainty for each year\n",
        "for year in years:\n",
        "    mean_temp_world.append(global_temp_land_cleaned[global_temp_land_cleaned['dt'].dt.year == year]['LandAverageTemperature'].mean())\n",
        "    mean_temp_world_uncertainty.append(global_temp_land_cleaned[global_temp_land_cleaned['dt'].dt.year == year]['LandAverageTemperatureUncertainty'].mean())\n",
        "\n",
        "# Create a Scatter plot for uncertainty (top)\n",
        "trace0 = go.Scatter(\n",
        "    x = years,\n",
        "    y = np.array(mean_temp_world) + np.array(mean_temp_world_uncertainty),\n",
        "    fill= None,\n",
        "    mode='lines',\n",
        "    name='Uncertainty top',\n",
        "    line=dict(\n",
        "                color='rgb(0, 255, 255)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a Scatter plot for uncertainty (bottom)\n",
        "trace1 = go.Scatter(\n",
        "    x = years,\n",
        "    y = np.array(mean_temp_world) - np.array(mean_temp_world_uncertainty),\n",
        "    fill='tonexty',\n",
        "    mode='lines',\n",
        "    name='Uncertainty bot',\n",
        "    line=dict(\n",
        "        color='rgb(0, 255, 255)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a Scatter plot for average temperature\n",
        "trace2 = go.Scatter(\n",
        "    x = years,\n",
        "    y = mean_temp_world,\n",
        "    name='Average Temperature',\n",
        "    line=dict(\n",
        "        color='rgb(199, 121, 093)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Combine traces into data list\n",
        "data = [trace0, trace1, trace2]\n",
        "\n",
        "# Create plot\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(title='year'),\n",
        "    yaxis=dict(title='Average Temperature, C'),\n",
        "    title='Average land temperature in world',\n",
        "    showlegend = False)\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.iplot(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed9udSvLpbBN"
      },
      "source": [
        "From the plot, we can see that the average land temperature of the world stayed relatively consistent from 1750 to the 1950s. However, since then, we observe in our plot, that there is a steady upwards trend in average land temperature. See the below plot for a comparison in average land temperature from 1900 to 1950 versus average land temperature from 1950 - 2015."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzFBkHwlq5Gj"
      },
      "outputs": [],
      "source": [
        "# Extract the year from a date\n",
        "years = np.unique(global_temp_land_cleaned['dt'].dt.year)\n",
        "mean_temp_world = []\n",
        "mean_temp_world_uncertainty = []\n",
        "\n",
        "# Calculate mean temperature and uncertainty for each year\n",
        "for year in years:\n",
        "    mean_temp_world.append(global_temp_land_cleaned[global_temp_land_cleaned['dt'].dt.year == year]['LandAverageTemperature'].mean())\n",
        "    mean_temp_world_uncertainty.append(global_temp_land_cleaned[global_temp_land_cleaned['dt'].dt.year == year]['LandAverageTemperatureUncertainty'].mean())\n",
        "\n",
        "# Filter data for two date ranges\n",
        "years_1900_1950 = np.unique(global_temp_land_cleaned[(global_temp_land_cleaned['dt'].dt.year >= 1900) & (global_temp_land_cleaned['dt'].dt.year <= 1950)]['dt'].dt.year)\n",
        "years_1950_2015 = np.unique(global_temp_land_cleaned[(global_temp_land_cleaned['dt'].dt.year > 1950) & (global_temp_land_cleaned['dt'].dt.year <= 2015)]['dt'].dt.year)\n",
        "\n",
        "# Create a Scatter plot for uncertainty (top) - 1900-1950\n",
        "trace0_1900_1950 = go.Scatter(\n",
        "    x=years_1900_1950,\n",
        "    y=np.array(mean_temp_world)[years_1900_1950 - years.min()] + np.array(mean_temp_world_uncertainty)[years_1900_1950 - years.min()],\n",
        "    fill=None,\n",
        "    mode='lines',\n",
        "    name='Uncertainty top (1900-1950)',\n",
        "    line=dict(\n",
        "        color='rgb(0, 255, 255)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a Scatter plot for uncertainty (bottom) - 1900-1950\n",
        "trace1_1900_1950 = go.Scatter(\n",
        "    x=years_1900_1950,\n",
        "    y=np.array(mean_temp_world)[years_1900_1950 - years.min()] - np.array(mean_temp_world_uncertainty)[years_1900_1950 - years.min()],\n",
        "    fill='tonexty',\n",
        "    mode='lines',\n",
        "    name='Uncertainty bot (1900-1950)',\n",
        "    line=dict(\n",
        "        color='rgb(0, 255, 255)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a Scatter plot for average temperature - 1900-1950\n",
        "trace2_1900_1950 = go.Scatter(\n",
        "    x=years_1900_1950,\n",
        "    y=np.array(mean_temp_world)[years_1900_1950 - years.min()],\n",
        "    name='Average Temperature (1900-1950)',\n",
        "    line=dict(\n",
        "        color='rgb(199, 121, 093)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a Scatter plot for uncertainty (top) - 1950-2015\n",
        "trace0_1950_2015 = go.Scatter(\n",
        "    x=years_1950_2015,\n",
        "    y=np.array(mean_temp_world)[years_1950_2015 - years.min()] + np.array(mean_temp_world_uncertainty)[years_1950_2015 - years.min()],\n",
        "    fill=None,\n",
        "    mode='lines',\n",
        "    name='Uncertainty top (1950-2015)',\n",
        "    line=dict(\n",
        "        color='rgb(255, 0, 0)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a Scatter plot for uncertainty (bottom) - 1950-2015\n",
        "trace1_1950_2015 = go.Scatter(\n",
        "    x=years_1950_2015,\n",
        "    y=np.array(mean_temp_world)[years_1950_2015 - years.min()] - np.array(mean_temp_world_uncertainty)[years_1950_2015 - years.min()],\n",
        "    fill='tonexty',\n",
        "    mode='lines',\n",
        "    name='Uncertainty bot (1950-2015)',\n",
        "    line=dict(\n",
        "        color='rgb(255, 0, 0)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a Scatter plot for average temperature - 1950-2015\n",
        "trace2_1950_2015 = go.Scatter(\n",
        "    x=years_1950_2015,\n",
        "    y=np.array(mean_temp_world)[years_1950_2015 - years.min()],\n",
        "    name='Average Temperature (1950-2015)',\n",
        "    line=dict(\n",
        "        color='rgb(0, 128, 0)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Combine traces into data list for both date ranges\n",
        "data = [trace0_1900_1950, trace1_1900_1950, trace2_1900_1950, trace0_1950_2015, trace1_1950_2015, trace2_1950_2015]\n",
        "\n",
        "# Create plot for both date ranges\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(title='year'),\n",
        "    yaxis=dict(title='Average Temperature, C'),\n",
        "    title='Average land temperature in world',\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "# Display the plot\n",
        "py.iplot(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ00-J2irYfJ"
      },
      "source": [
        "Clearly, there is a large disparity in the average temperature changes between these time periods. Specifically, the temperature from 1900 - 1950 fluctuates around 8.5 degrees, while from 1950 - 2015, the average temperature is steadily rising to almost 10 degrees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqi6DZRHsow"
      },
      "source": [
        "### 3.1.3 Stationarity in Global Land Temperatures Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zly5BqcpHsow"
      },
      "source": [
        "Time series data often requires data to be stationary, meaning the mean and variance do not change over time. If this property is violated, then the data has some inherent trend, which is the case in climate change data. To check, we will set our alpha to be 0.05 and perform Dickey-Fuller test from *adfuller* package for stationarity. Our null hypothesis is that our data is not stationary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylqOy2jTHsow"
      },
      "outputs": [],
      "source": [
        "# Checking the hypothesis\n",
        "print(\"The p-value for the ADF test in global_temp_land_cleaned is \", adfuller(global_temp_land_cleaned['LandAverageTemperature'])[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMb_q4kWHsoy"
      },
      "source": [
        "Since the p-value for *global_temp_land_cleaned* is less than alpha (0.05), **we reject the null hypothesis**. The *global_temp_land_cleaned* data is stationary. We can proceed with autocorrelations check."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZwXWTRzHsoy"
      },
      "source": [
        "### 3.1.4 Autocorrelations Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8oeKGSCseYJ"
      },
      "source": [
        "Autocorrelation is the correlation between two observations at different points in a time series data. When correlations are present, past values might influence the current value. The following code is visually inspecting the autocorrelation and partial autocorrelation of the 'LandAverageTemperature' time series data to gain insights into potential temporal patterns and dependencies in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaBBXCXiHsoz"
      },
      "outputs": [],
      "source": [
        "# Creating autocorrelation plot\n",
        "plot_acf(global_temp_land_cleaned['LandAverageTemperature'])\n",
        "plot_pacf(global_temp_land_cleaned['LandAverageTemperature'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBdfLY47Hso0"
      },
      "source": [
        "In the autocorrelation plots, we see significant spikes and patterns. This suggests that the land temperatures have a presence of seasonality, which is clearly true because temperatures change based on weather patterns, which display a seasonal pattern.\n",
        "\n",
        "In the partial autocorrelation plot, we see the same wave-like pattern, which highlights the presence of seasonality. It's interesting to see that the beginning of the plot has much higher magnitudes, and over time, the peaks get smaller in magnitude (i.e. there exists a dampening effect). This seems to mean that the influence of past cycles is weakening over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MANRxryVHso0"
      },
      "source": [
        "## 3.2 EDA in Global Land and Ocean Temperatures Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBhkDj1IuV2Q"
      },
      "source": [
        "The following section conducts exploratory data analysis on the Global Land and Ocean Temperatures Data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8cxBVywHso0"
      },
      "source": [
        "### 3.2.1 Visualize Trends in Land and Ocean Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkAmr-Ggujsc"
      },
      "source": [
        "The type of plot being created in this code is a line plot. It is used to visualize the trend in land and ocean average temperature over time. The plot includes two lines:\n",
        "\n",
        "- Monthly Average Temperature: This line represents the monthly average land temperature over time. It is drawn with some transparency (alpha=0.5) to show individual data points.\n",
        "\n",
        "- 10-Year Rolling Average: This line represents the 10-year rolling average of the land temperature. It is calculated to smooth out short-term fluctuations and highlight long-term trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiqNJJLWHso0"
      },
      "outputs": [],
      "source": [
        "# Calculate 10_year_rolling_avg\n",
        "global_temp_land_and_ocean_cleaned['10_year_rolling_avg_ocean'] = global_temp_land_and_ocean_cleaned['LandAndOceanAverageTemperature'].rolling(window=120).mean()\n",
        "\n",
        "# Plot monthly average temperature and 10-year rolling average\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(global_temp_land_and_ocean_cleaned['dt'], global_temp_land_and_ocean_cleaned['LandAndOceanAverageTemperature'], label='Monthly Average Temperature', alpha=0.5)\n",
        "plt.plot(global_temp_land_and_ocean_cleaned['dt'], global_temp_land_and_ocean_cleaned['10_year_rolling_avg_ocean'], label='10-Year Rolling Average', color='red', linewidth=2)\n",
        "plt.title('Land and Ocean Average Temperature Over Time with 10 Years Rolling Average')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature (C)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS-Yjl5GHso0"
      },
      "source": [
        "Compared to the land temperature trend, the land and ocean temperature trend has a significantly steeper slope, indicating that ocean temperature has increased more over time compared to land temperature, which is concerning since 71 percent of Earth's surface is water. This could indicate the non-stationarity of the land and ocean temperatures.\n",
        "\n",
        "Additionally, temperature warming is often noticed earlier in ocean temperates. This means that the steeper slope that we are seeing in this graph may be indicative of more extreme changes in land temperatures in the next few years."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn8B3Fm5Hso0"
      },
      "source": [
        "### 3.2.2 Interactive Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fifKEtidPNUi"
      },
      "source": [
        "This code creates another interactive Plotly line plot to illustrate the average land and ocean temperatures and their uncertainty over the years. The resulting interactive plot allows for a dynamic exploration of temperature trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84W-FOItHso0"
      },
      "outputs": [],
      "source": [
        "# Extract the year from a date\n",
        "years_ocean = np.unique(global_temp_land_and_ocean_cleaned['dt'].dt.year)\n",
        "mean_temp_world_ocean = []\n",
        "mean_temp_world_ccean_uncertainty = []\n",
        "\n",
        "# Calculate mean temperature and uncertainty for each year\n",
        "for year in years_ocean:\n",
        "    mean_temp_world_ocean.append(global_temp_land_and_ocean_cleaned[global_temp_land_and_ocean_cleaned['dt'].dt.year == year]['LandAndOceanAverageTemperature'].mean())\n",
        "    mean_temp_world_ccean_uncertainty.append(global_temp_land_and_ocean_cleaned[global_temp_land_and_ocean_cleaned['dt'].dt.year == year]['LandAndOceanAverageTemperatureUncertainty'].mean())\n",
        "\n",
        "# Create a Scatter plot for uncertainty (top)\n",
        "trace0 = go.Scatter(\n",
        "    x = years_ocean,\n",
        "    y = np.array(mean_temp_world_ocean) + np.array(mean_temp_world_ccean_uncertainty),\n",
        "    fill= None,\n",
        "    mode='lines',\n",
        "    name='Uncertainty top',\n",
        "    line=dict(\n",
        "                color='rgb(0, 255, 255)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a Scatter plot for uncertainty (bottom)\n",
        "trace1 = go.Scatter(\n",
        "    x = years_ocean,\n",
        "    y = np.array(mean_temp_world_ocean) - np.array(mean_temp_world_ccean_uncertainty),\n",
        "    fill='tonexty',\n",
        "    mode='lines',\n",
        "    name='Uncertainty bot',\n",
        "    line=dict(\n",
        "        color='rgb(0, 255, 255)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a Scatter plot for average temperature\n",
        "trace2 = go.Scatter(\n",
        "    x = years_ocean,\n",
        "    y = mean_temp_world_ocean,\n",
        "    name='Average Temperature',\n",
        "    line=dict(\n",
        "        color='rgb(199, 121, 093)',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Combine traces into data list\n",
        "data = [trace0, trace1, trace2]\n",
        "\n",
        "# Create plot\n",
        "layout = go.Layout(\n",
        "    xaxis=dict(title='year'),\n",
        "    yaxis=dict(title='Average Temperature, C'),\n",
        "    title='Average land and ocean temperature in world',\n",
        "    showlegend = False)\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.iplot(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YZAXcx3Hso0"
      },
      "source": [
        "The graph reiterates how there is a clear trend of global temperature increase in recent decades. An interesting finding from this graph shows us that average land and temperatures in the world have been increasing since before the 1950s (which is a commonly attributed starting point for the beginning of global warming, due to the rapid industrialization post World War II).\n",
        "\n",
        "Specifically, from observation, it seems like average land and ocean temperatures in the world have been increasing since the early 1900s. Scientists attribute this rise in temperature to the effects of early industrialization in the late 18th century and 19th century.\n",
        "\n",
        "It's also interesting to note that the effects of climate change, particularly warming, are often noticed earlier in average ocean temperatures compared to land temperatures is due to the inherent characteristics of the Earth's climate system and the distribution of heat. Thus, the rapid rise in average temperature from 2011 - 2015 could be a noteworthy factor when anticipating trends in average land temperature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1oddndtHso0"
      },
      "source": [
        "### 3.2.3 Stationarity in Global Land and Ocean Temperatures Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRaCJlwuHso0"
      },
      "outputs": [],
      "source": [
        "print(\"The p-value for the ADF test in global_temp_land_and_ocean_cleaned is \", adfuller(global_temp_land_and_ocean_cleaned['LandAndOceanAverageTemperature'])[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rms0vy2UHso0"
      },
      "source": [
        "Since the p-value for *global_temp_land_and_ocean_cleaned* is greater than alpha (0.05), **we fail to reject the null hypothesis**. As expected, the *global_temp_land_and_ocean_cleaned* data is not stationary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dyn0Cc0GgM_"
      },
      "source": [
        "### 3.2.4 Autocorrelations Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHuYH1kIGolZ"
      },
      "source": [
        "The following code is visually inspecting the autocorrelation and partial autocorrelation of the 'LandAndOceanAverageTemperature' time series data to gain insights into potential temporal patterns and dependencies in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiOw8QnaGKT7"
      },
      "outputs": [],
      "source": [
        "plot_acf(global_temp_land_and_ocean_cleaned['LandAndOceanAverageTemperature'])\n",
        "plot_pacf(global_temp_land_and_ocean_cleaned['LandAndOceanAverageTemperature'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cgUsQw5GrXi"
      },
      "source": [
        "Like in the autocorrelation plots for LandAverageTemperature, we see that the plots display seasonality.\n",
        "\n",
        "In the partial autocorrelation plot, we also see the seasonality. But the dampening effect in this graph is more dramatic, suggesting that temperature trends in recent years are becomming less reliant on the previous time steps and might be influenced by external factors or long-term trends. This phenomenon could be indicative of changing climate dynamics or human-induced impacts that are altering the traditional seasonal patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGkwT9gRHso1"
      },
      "source": [
        "## 3.3 EDA in Global Land Temperatures by State Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqC9YtqiHeEe"
      },
      "source": [
        "The following section conducts exploratory data analysis on the Global Land Temperatures by State Data. We will focus on doing our EDA on the United States."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvOtwnPp1wnp"
      },
      "outputs": [],
      "source": [
        "# Filter data for the United States\n",
        "us_data = global_temp_state_cleaned[global_temp_state_cleaned['Country'] == 'United States']\n",
        "\n",
        "# Replace Georgia (State) with Georgia\n",
        "us_data['State'] = us_data['State'].replace('Georgia (State)', 'Georgia')\n",
        "\n",
        "us_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA8F7rtSHeEr"
      },
      "source": [
        "### 3.3.1 Visualize Distribution of Temperatures for the United States"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PbRxl35dN00"
      },
      "source": [
        "Let's visualize the range of temperatures across different states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwQxZ28IpaeL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25, 5))\n",
        "sns.boxplot(x='State', y='AverageTemperature', data=us_data)\n",
        "\n",
        "# Adjust font size and rotation\n",
        "plt.title(f'Boxplot of Temperature for Each State Over Time', fontsize=12)\n",
        "plt.xlabel('State', fontsize=10)\n",
        "plt.ylabel('Average Temperature', fontsize=10)\n",
        "plt.xticks(fontsize=10, rotation=45, ha='right')  # Adjust rotation for state labels\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsrsv1HHq9SP"
      },
      "source": [
        "As we can see, Alaska and Hawaii can be categorized as outliers in terms of their median temperature and range: Alaska has the widest range of temperatures with the lowest median, while Hawaii has the narrowest range of temperatures with the highest median. But the graph does not give us information about how the temperature in each state changes over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0icokfnHeEt"
      },
      "source": [
        "### 3.3.2 Visualizing Annual Trends"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34dd1O4SeFg3"
      },
      "source": [
        "Let's now visualize how temperature in each state has changed over time using an interactive map. Using the slider, we can see the average temperature in each state by hovering over the map and seeing how the color scale changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1KwWIU_2fmD"
      },
      "outputs": [],
      "source": [
        "# Extract the year from the 'dt' column\n",
        "us_data['Year'] = us_data['dt'].dt.year\n",
        "\n",
        "# Group by 'State' and 'Year' and calculate the mean temperature\n",
        "average_temp_by_state = us_data.groupby(['State', 'Year'])['AverageTemperature'].mean().reset_index()\n",
        "\n",
        "# Fetch the US states GeoJSON file\n",
        "geojson_url = 'https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json'\n",
        "with urllib.request.urlopen(geojson_url) as url:\n",
        "    us_states_geojson = json.loads(url.read().decode())\n",
        "\n",
        "# Extract the 'features' part from GeoJSON\n",
        "features = us_states_geojson['features']\n",
        "\n",
        "# Create a DataFrame from GeoJSON features\n",
        "geojson_df = pd.json_normalize(features)\n",
        "\n",
        "# Merge temperature data with GeoJSON file based on state names\n",
        "map_data = pd.merge(geojson_df, average_temp_by_state, how='left', left_on='properties.name', right_on='State')\n",
        "\n",
        "# Create a choropleth map using Plotly Express with a slider for the year\n",
        "fig = px.choropleth_mapbox(map_data, geojson=us_states_geojson, locations=map_data['properties.name'],\n",
        "                           featureidkey=\"properties.name\",\n",
        "                           color=\"AverageTemperature\",\n",
        "                           color_continuous_scale=\"Viridis\",\n",
        "                           mapbox_style=\"carto-positron\",\n",
        "                           zoom=2, center={\"lat\": 50, \"lon\": -110},\n",
        "                           opacity=0.5,\n",
        "                           labels={'AverageTemperature': 'Average Temperature'},\n",
        "                           title='Average Temperature in US States Over Time',\n",
        "                           animation_frame='Year',  # Add animation frame for the year slider\n",
        "                           hover_data={'properties.name': False, 'State': True, 'Year': True},  # Customize hover text\n",
        "                           height=800,  # Set the height of the plot\n",
        "                           width=1000,\n",
        "                           )\n",
        "\n",
        "# Show the map\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3M01s64v05N"
      },
      "source": [
        "In year 1743, there are only data from states on the Eastern half of the US, and we can see a clear gradient of temperature change from the purple, colder climate in the northern states to the greenish-yellow, warmer climate in the southern states.\n",
        "\n",
        "As time progresses, we can see that Alaska has largely remained purple, meaning its average temperature has not changed much over time, but we only rarely see hints of purples at the northern states. This pattern started during the 1800s, and the average temperature across all states does not seem to have much changes over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tkd_iYAHeEt"
      },
      "source": [
        "### 3.3.3 Stationarity in US State Temperatures Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6srdDwHL3jXL"
      },
      "outputs": [],
      "source": [
        "print(\"The p-value for the ADF test in us_data is \", adfuller(us_data['AverageTemperature'])[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2abDawQL4MtX"
      },
      "source": [
        "The p-value (2.938313973490292e-07) is a very small value, close to zero.\n",
        "\n",
        "The small p-value obtained suggests that we can reject the null hypothesis, and the data is likely stationary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFZ_41FIHeEt"
      },
      "source": [
        "### 3.3.4 Autocorrelations Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZ62K4MI4U1O"
      },
      "outputs": [],
      "source": [
        "plot_acf(us_data['AverageTemperature'])\n",
        "plot_pacf(us_data['AverageTemperature'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HATbygu4kf2"
      },
      "source": [
        "Like the two autocorrelation checks above, we again see that the plots display seasonality, but the dampening effect in this partial autocorrelation plot is similar to the one for Global Land Temperatures data, further indicating that there is a more significant change in climate whenever ocean data is introduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNWdigrO49g7"
      },
      "source": [
        "### 3.3.5 Seasonality in the US Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FR1uhCm5Azl"
      },
      "outputs": [],
      "source": [
        "us_data['Month'] = us_data['dt'].dt.month\n",
        "sns.boxplot(x='Month', y='AverageTemperature', data=us_data)\n",
        "plt.title('Seasonal Boxplot of Temperature')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82LwXNUIC-4p"
      },
      "source": [
        "As expected, July has the highest average temperature, being in the middle of summer; and January has the lowest average temperature for being the coldest month in the year.\n",
        "\n",
        "We will pick the northernmost state besides Alaska (Minnesota), middle state (Pennsylvania), and southernmost state (Florida) from our data to visualize how seasonality differs depending on latitude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5cVqWYulBWs"
      },
      "outputs": [],
      "source": [
        "# Extract MN, PA, and FL data\n",
        "mn = us_data[us_data['State'] == 'Minnesota']\n",
        "pa = us_data[us_data['State'] == 'Pennsylvania']\n",
        "fl = us_data[us_data['State'] == 'Florida']\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Creating a boxplot for Minnesota, Pennsylvania, and Florida\n",
        "sns.boxplot(x='Month', y='AverageTemperature', data=mn, color='blue', showfliers=False)\n",
        "sns.boxplot(x='Month', y='AverageTemperature', data=pa, color='red', showfliers=False)\n",
        "sns.boxplot(x='Month', y='AverageTemperature', data=fl, color='green', showfliers=False)\n",
        "\n",
        "# Adding a title, labels\n",
        "plt.title('Seasonal Boxplot Overlay for Minnesota, Pennsylvania, and Florida')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Temperature')\n",
        "\n",
        "# Adding a legend\n",
        "mn_patch = plt.Rectangle((0,0),1,1,fc='blue', edgecolor = 'black')\n",
        "pa_patch = plt.Rectangle((0,0),1,1,fc='red', edgecolor = 'black')\n",
        "fl_patch = plt.Rectangle((0,0),1,1,fc='green', edgecolor = 'black')\n",
        "plt.legend([mn_patch, pa_patch, fl_patch], ['Minnesota', 'Pennsylvania', 'Florida'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncjy7NEIl4It"
      },
      "source": [
        "The trend above shows that during the winter months, there is more temperature variation among states, with temperature ranging from around 20 to below -20 Celcius. While during the summer months, the temperature range across the three latitudes is smaller, ranging from 30 to 15 Celcius."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79VyHuSZHso1"
      },
      "source": [
        "## 3.4 EDA in Global Land Temperatures by Country Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq-5-UdJPjzD"
      },
      "source": [
        "### 3.4.1 Averaged Dynamic Exploration of Temperature Trends Using Globe\n",
        "Dynamic exploration of temperature trends via a Plotly line plot for global land temperatures by country."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOLsZItFHso1"
      },
      "outputs": [],
      "source": [
        "countries = np.unique(global_temp_country_cleaned['Country'])\n",
        "avg_temp_country = []\n",
        "for country in countries:\n",
        "    avg_temp_country.append(global_temp_country_cleaned[global_temp_country_cleaned['Country'] == country]['AverageTemperature'].mean())\n",
        "\n",
        "#interactive\n",
        "data = [dict(\n",
        "        type = 'choropleth',\n",
        "        locations = countries,\n",
        "        z = avg_temp_country,\n",
        "        locationmode = 'country names',\n",
        "        text = countries,\n",
        "        marker = dict(\n",
        "            line = dict(color = 'rgb(0,0,0)', width = 1)),\n",
        "            colorbar = dict(autotick = True, tickprefix = '',\n",
        "            title = '# Average\\nTemperature,\\nC')\n",
        "            )\n",
        "       ]\n",
        "\n",
        "layout = dict(\n",
        "    title = 'Average land temperature in countries',\n",
        "    geo = dict(\n",
        "        showframe = False,\n",
        "        showocean = True,\n",
        "        oceancolor = 'rgb(0,255,255)',\n",
        "        projection = dict(\n",
        "        type = 'orthographic',\n",
        "            rotation = dict(\n",
        "                    lon = 60,\n",
        "                    lat = 10),\n",
        "        ),\n",
        "        lonaxis =  dict(\n",
        "                showgrid = True,\n",
        "                gridcolor = 'rgb(102, 102, 102)'\n",
        "            ),\n",
        "        lataxis = dict(\n",
        "                showgrid = True,\n",
        "                gridcolor = 'rgb(102, 102, 102)'\n",
        "                )\n",
        "            ),\n",
        "        )\n",
        "\n",
        "fig = dict(data=data, layout=layout)\n",
        "py.iplot(fig, validate=False, filename='worldmap')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjiCr0wtF4DC"
      },
      "source": [
        "These plots align with our understanding of each country's temperatures in relation to the globe. We see that countries that are closer to the equater have higher average temperatures throughout the year (Australia, Brazil, India)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsTNn5ebXNyg"
      },
      "source": [
        "### 3.4.2 Dynamic Exploration of Temperature Trends per Country Over Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofeR7sqMXdyQ"
      },
      "source": [
        "This code generates an interactive line plot to visualize the average monthly temperatures for each country."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrnQOF1wTpi9"
      },
      "outputs": [],
      "source": [
        "# Function to find the best match for each country in temperature data\n",
        "def find_best_match(country, choices):\n",
        "    return process.extractOne(country, choices)\n",
        "\n",
        "# Assuming your DataFrame is named global_temp_country_cleaned\n",
        "# Extract the year from the 'dt' column\n",
        "global_temp_country_cleaned['Year'] = global_temp_country_cleaned['dt'].dt.year\n",
        "\n",
        "# Group by 'Country' and 'Year' and calculate the mean temperature\n",
        "average_temp_by_country = global_temp_country_cleaned.groupby(['Country', 'Year'])['AverageTemperature'].mean().reset_index()\n",
        "\n",
        "# Load the world GeoJSON file directly from GitHub\n",
        "world_geojson_url = 'https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/geojson/ne_110m_admin_0_countries.geojson'\n",
        "world_geojson = gpd.read_file(world_geojson_url)\n",
        "\n",
        "# Clean names to match\n",
        "global_temp_country_cleaned['Country'] = global_temp_country_cleaned['Country'].str.strip().str.lower()\n",
        "world_geojson['ADMIN'] = world_geojson['ADMIN'].str.strip().str.lower()\n",
        "\n",
        "# Apply the function to find the best match for each country in temperature data\n",
        "temperature_data_countries = global_temp_country_cleaned['Country'].unique()\n",
        "geojson_countries = world_geojson['ADMIN'].unique()\n",
        "\n",
        "matches = {country: find_best_match(country, geojson_countries) for country in temperature_data_countries}\n",
        "\n",
        "# Display the unmatched countries for further inspection\n",
        "unmatched_countries = {country for country, (match, score) in matches.items() if score < 90}\n",
        "\n",
        "# Create a dictionary to map temperature data countries to GeoJSON countries\n",
        "country_name_mapping = {country: match for country, (match, score) in matches.items()}\n",
        "\n",
        "# Map the countries in the DataFrame\n",
        "global_temp_country_cleaned['Country'] = global_temp_country_cleaned['Country'].map(country_name_mapping).fillna(global_temp_country_cleaned['Country'])\n",
        "\n",
        "# Merge temperature data with GeoJSON file based on country names\n",
        "merged = world_geojson.merge(average_temp_by_country, left_on='ADMIN', right_on='Country', how='left')\n",
        "merged = merged.sort_values(by='Year')\n",
        "\n",
        "# Filter the data for every 10 years\n",
        "filtered_data = merged[merged['Year'] % 10 == 0]\n",
        "\n",
        "# Create a choropleth map using Plotly Express with a slider for every 10 years\n",
        "fig = px.choropleth_mapbox(filtered_data, geojson=world_geojson, locations=filtered_data['ADMIN'],\n",
        "                            featureidkey=\"properties.ADMIN\",\n",
        "                            color=\"AverageTemperature\",\n",
        "                          color_continuous_scale=\"Viridis\",\n",
        "                            mapbox_style=\"carto-positron\",\n",
        "                            zoom=0.5, center={\"lat\": 30, \"lon\": 0},  # Adjust center and zoom as needed\n",
        "                            opacity=0.5,\n",
        "                            labels={'AverageTemperature': 'Average Temperature'},\n",
        "                            title='Average Temperature Worldwide Over Time (Every 10 Years)',\n",
        "                            animation_frame='Year',  # Use 'Year' for the slider\n",
        "                            hover_data={'ADMIN': False, 'Country': True, 'Year': True},  # Customize hover text\n",
        "                            height=800,  # Set the height of the plot\n",
        "                            width=1000,\n",
        "                            animation_group='ADMIN',  # Use 'ADMIN' for consistent coloring\n",
        "                            range_color=[merged['AverageTemperature'].min(), merged['AverageTemperature'].max()]  # Set color range\n",
        "                            )\n",
        "\n",
        "# Show the map\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v0eWU9TWfl7"
      },
      "source": [
        "These plots align with our understanding of each country's temperatures throughout time. We can see that temperatures are clearly rising over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDz4CP96htPr"
      },
      "source": [
        "### 3.4.3 Autocorrelations Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8QRTS2shz2z"
      },
      "outputs": [],
      "source": [
        "plot_acf(global_temp_country_cleaned['AverageTemperature'], lags=20)\n",
        "plt.show()\n",
        "\n",
        "plot_pacf(global_temp_country_cleaned['AverageTemperature'], lags=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfZXv4I7rpN4"
      },
      "source": [
        "Unlike the three plots above, there is no obvious weekly or monthly pattern, which makes sense because our data contains countries from all around the world, so it is not possible to capture seasonality that is uniform across all those countries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAYAgZGtJXki"
      },
      "source": [
        "### 3.4.4 Seasonality in Global Land Temperatures by Country Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVsLRRmLJgyp"
      },
      "outputs": [],
      "source": [
        "# Adding latitude to country data\n",
        "# Function to fetch latitude for a given country\n",
        "def get_latitude(country, geolocator):\n",
        "    location = geolocator.geocode(country)\n",
        "    return location.latitude if location else None\n",
        "\n",
        "# Extract unique country names from the DataFrame\n",
        "unique_countries = global_temp_country_cleaned['Country'].unique()\n",
        "\n",
        "# Initialize the geolocator\n",
        "geolocator = Nominatim(user_agent=\"geo_locator\")\n",
        "\n",
        "# Create a DataFrame to store unique country names and their latitudes\n",
        "country_latitudes_df = pd.DataFrame({'Country': unique_countries})\n",
        "\n",
        "# Fetch latitude for each unique country\n",
        "country_latitudes_df['Latitude'] = country_latitudes_df['Country'].apply(lambda country: get_latitude(country, geolocator))\n",
        "\n",
        "# Merge latitude information into the main DataFrame\n",
        "global_temp_country_cleaned = pd.merge(global_temp_country_cleaned, country_latitudes_df, on='Country', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ25C14KMILZ"
      },
      "outputs": [],
      "source": [
        "latitude_threshold = 0\n",
        "\n",
        "# Split the DataFrame into Northern and Southern Hemisphere\n",
        "northern_hemisphere_df = global_temp_country_cleaned[global_temp_country_cleaned['Latitude'] >= latitude_threshold]\n",
        "southern_hemisphere_df = global_temp_country_cleaned[global_temp_country_cleaned['Latitude'] < latitude_threshold]\n",
        "\n",
        "# Assuming 'northern_hemisphere_df' and 'southern_hemisphere_df' are your DataFrames\n",
        "# Convert 'dt' to datetime format if not already done\n",
        "northern_hemisphere_df['dt'] = pd.to_datetime(northern_hemisphere_df['dt'])\n",
        "southern_hemisphere_df['dt'] = pd.to_datetime(southern_hemisphere_df['dt'])\n",
        "\n",
        "# Extract Month from the 'dt' column\n",
        "northern_hemisphere_df['Month'] = northern_hemisphere_df['dt'].dt.month\n",
        "southern_hemisphere_df['Month'] = southern_hemisphere_df['dt'].dt.month\n",
        "\n",
        "# Plotting Monthly Box Plots for Northern Hemisphere\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(x='Month', y='AverageTemperature', data=northern_hemisphere_df)\n",
        "plt.title('Northern Hemisphere - Monthly Average Temperature')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Temperature')\n",
        "plt.show()\n",
        "\n",
        "# Plotting Monthly Box Plots for Southern Hemisphere\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(x='Month', y='AverageTemperature', data=southern_hemisphere_df)\n",
        "plt.title('Southern Hemisphere - Monthly Average Temperature')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Temperature')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM_mo_HvteuR"
      },
      "source": [
        "The two plots above showed an interesting trend: the Northern Hemisphere has more variation in temperature during the colder months of January, February, November, and December as opposed to the small ranges during July and August; while the Southern Hemisphere has a pretty uniform variance across all months."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV8fzArnHso1"
      },
      "source": [
        "## 3.5 EDA in Global Land Temperatures by City Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LcY0_tEHso1"
      },
      "source": [
        "### 3.5.1 Exploration of Relationship Between Latitude and Temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pALTEVQYHso1"
      },
      "outputs": [],
      "source": [
        "latitude_df = global_temp_city_cleaned.sort_values(by='Latitude')\n",
        "\n",
        "avg_temp_by_latitude = latitude_df.groupby('Latitude')['AverageTemperature'].mean()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.bar(avg_temp_by_latitude.index, avg_temp_by_latitude.values, color='skyblue')\n",
        "plt.xlabel('Latitude')\n",
        "plt.ylabel('Average Average Temperature (C)')\n",
        "plt.title('Average Average Temperature vs Latitude')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQF89rV-Hso1"
      },
      "source": [
        "This plot emphasizes what we already know about temperature trends in relation to latitude. Specifically, near the equator (i.e. latitude = 0), temperatures are generally higher due to the direct sunlight received, while temperatures decrease towards the poles where sunlight is spread out over a larger area."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDYQvZ7LHso1"
      },
      "source": [
        "### 3.5.2 Average Temperature Contour Plot on World Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggCqAXT9Hso1"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 10))\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "ax.add_feature(cfeature.COASTLINE)\n",
        "\n",
        "# We set the number of contour lines, or evenly spaced intervals between the minimum and maximum values of average temperature to be 200 to see more nuanced changes in temperature in different areas of the world\n",
        "contour = plt.tricontourf(global_temp_city_cleaned['Longitude'], global_temp_city_cleaned['Latitude'], global_temp_city_cleaned['AverageTemperature'],\n",
        "                          transform=ccrs.PlateCarree(), cmap='coolwarm', levels=np.linspace(min(global_temp_city_cleaned['AverageTemperature']), max(global_temp_city_cleaned['AverageTemperature']), 200))\n",
        "\n",
        "cbar = plt.colorbar(contour, orientation='vertical', pad=0.02, aspect=16, shrink=0.8)\n",
        "cbar.set_label('Average Temperature (C)', rotation=270, labelpad=20)\n",
        "\n",
        "plt.title('Average Temperature Contour Plot on World Map')\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcwvUPrZtihe"
      },
      "source": [
        "This heatmap hows that inner land areas in parts of Africa, India, and the US contained the highest average temperatures, while areas corresponding to parts of Russia and Canada have the lowest average temperatures. But to see the cities data in more detail, we would need interactive graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1dsSKEqeImh"
      },
      "source": [
        "### 3.5.3 Average Temperature Interactive Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9ZmLvhbuIid"
      },
      "source": [
        "Let's take a look at the average temperature in each city using an interactive map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z_SQgZNeN0o"
      },
      "outputs": [],
      "source": [
        "# Convert Latitude and Longitude to numerical values if they are in string format\n",
        "if global_temp_city_cleaned['Latitude'].dtype == 'object':\n",
        "    global_temp_city_cleaned['Latitude'] = global_temp_city_cleaned['Latitude'].str.extract('(\\d+\\.\\d+)').astype(float)\n",
        "\n",
        "if global_temp_city_cleaned['Longitude'].dtype == 'object':\n",
        "    global_temp_city_cleaned['Longitude'] = global_temp_city_cleaned['Longitude'].str.extract('(\\d+\\.\\d+)').astype(float)\n",
        "\n",
        "# Group by Latitude and Longitude and calculate the average temperature\n",
        "average_temp_df = global_temp_city_cleaned.groupby(['Latitude', 'Longitude']).agg({\n",
        "    'City': 'first',\n",
        "    'AverageTemperature': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Normalize 'AverageTemperature' for sizing points on the plot\n",
        "min_temp = average_temp_df['AverageTemperature'].min()\n",
        "max_temp = average_temp_df['AverageTemperature'].max()\n",
        "average_temp_df['NormalizedTemperature'] = (average_temp_df['AverageTemperature'] - min_temp) / (max_temp - min_temp)\n",
        "\n",
        "# Manually set center and zoom level for the desired region\n",
        "center_lat = 30  # Center latitude\n",
        "center_lon = 40  # Center longitude\n",
        "zoom = 6  # Zoom level\n",
        "\n",
        "# Create an interactive map using plotly express\n",
        "fig = px.scatter_geo(\n",
        "    average_temp_df,\n",
        "    lat='Latitude',\n",
        "    lon='Longitude',\n",
        "    text='City',\n",
        "    size='NormalizedTemperature',  # Use normalized temperature for sizing\n",
        "    color='AverageTemperature',\n",
        "    color_continuous_scale='Viridis',\n",
        "    projection='natural earth',\n",
        "    title='Average Temperature Map',\n",
        "    size_max=15  # Smaller dot sizes\n",
        ")\n",
        "\n",
        "# Add hover information\n",
        "fig.update_traces(hovertemplate='<b>%{text}</b><br>Temperature: %{marker.color:.2f}C')\n",
        "\n",
        "# Customize layout for readability\n",
        "fig.update_layout(\n",
        "    geo=dict(\n",
        "        showcoastlines=True,\n",
        "        coastlinecolor=\"black\",\n",
        "        center=dict(lat=center_lat, lon=center_lon),\n",
        "        projection_scale=zoom,\n",
        "    ),\n",
        "    font=dict(size=8),  # Smaller font size for city names\n",
        "    geo_bgcolor=\"white\",  # Change background color\n",
        "    title=dict(font=dict(size=20)),  # Larger title font size\n",
        "    height=800,  # Set the height of the map\n",
        "    width=1200,  # Set the width of the map\n",
        "    margin=dict(l=0, r=0, b=0, t=40)  # Adjust margin for better use of space\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59dkrRv3t0P_"
      },
      "source": [
        "As we can see from the color, the cities around the equator are more yellow, meaning they have a higher average temperature. However, this graph does not give us information on average temperature over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh0PNtMCeRPH"
      },
      "source": [
        "### 3.5.4 Time-Series Temperature Interactive Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK4ErDCkugsv"
      },
      "source": [
        "Let's visualize the temperature data again, but adding a slider to see how temperature changes over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyxS2AfHeVNC"
      },
      "outputs": [],
      "source": [
        "# Convert 'dt' to datetime format\n",
        "global_temp_city_cleaned['dt'] = pd.to_datetime(global_temp_city_cleaned['dt'], errors='coerce')\n",
        "\n",
        "# Convert Latitude and Longitude to numerical values if they are in string format\n",
        "global_temp_city_cleaned['Latitude'] = pd.to_numeric(global_temp_city_cleaned['Latitude'], errors='coerce')\n",
        "global_temp_city_cleaned['Longitude'] = pd.to_numeric(global_temp_city_cleaned['Longitude'], errors='coerce')\n",
        "\n",
        "# Group by Latitude, Longitude, and the nearest 10-year interval, and calculate the average temperature\n",
        "global_temp_city_cleaned['Year'] = (global_temp_city_cleaned['dt'].dt.year // 10) * 10\n",
        "average_temp_df = global_temp_city_cleaned.groupby(['Latitude', 'Longitude', 'Year']).agg({\n",
        "    'City': 'first',\n",
        "    'AverageTemperature': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Sort the DataFrame by 'Year' for correct animation order\n",
        "average_temp_df = average_temp_df.sort_values('Year')\n",
        "\n",
        "# Normalize 'AverageTemperature' for sizing points on the plot\n",
        "min_temp = average_temp_df['AverageTemperature'].min()\n",
        "max_temp = average_temp_df['AverageTemperature'].max()\n",
        "average_temp_df['NormalizedTemperature'] = (average_temp_df['AverageTemperature'] - min_temp) / (max_temp - min_temp)\n",
        "\n",
        "# Manually set center and zoom level for the desired region\n",
        "center_lat = 30  # Center latitude\n",
        "center_lon = 40  # Center longitude\n",
        "zoom = 6  # Zoom level\n",
        "\n",
        "# Create an interactive map using plotly express\n",
        "fig = px.scatter_geo(\n",
        "    average_temp_df,\n",
        "    lat='Latitude',\n",
        "    lon='Longitude',\n",
        "    text='City',\n",
        "    size='NormalizedTemperature',  # Use normalized temperature for sizing\n",
        "    color='AverageTemperature',\n",
        "    color_continuous_scale='Viridis',\n",
        "    animation_frame='Year',  # Add animation frame for the slider\n",
        "    projection='natural earth',\n",
        "    title='Average Temperature Map',\n",
        "    size_max=15  # Smaller dot sizes\n",
        ")\n",
        "\n",
        "# Add hover information\n",
        "fig.update_traces(hovertemplate='<b>%{text}</b><br>Temperature: %{marker.color:.2f}C')\n",
        "\n",
        "# Customize layout for readability\n",
        "fig.update_layout(\n",
        "    geo=dict(\n",
        "        showcoastlines=True,\n",
        "        coastlinecolor=\"black\",\n",
        "        center=dict(lat=center_lat, lon=center_lon),\n",
        "        projection_scale=zoom,\n",
        "    ),\n",
        "    font=dict(size=8),  # Smaller font size for city names\n",
        "    geo_bgcolor=\"white\",  # Change background color\n",
        "    title=dict(font=dict(size=20)),  # Larger title font size\n",
        "    margin=dict(l=0, r=0, b=0, t=40),  # Adjust margin for better use of space\n",
        "    height=800,  # Set the height of the map\n",
        "    width=1200,  # Set the width of the map\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEMJd2XWt8C9"
      },
      "source": [
        "Similar to the interative map for the states data, in the 1700s, the northern cities were largely colored purple and the southern cities were mainly colored yellow, indicating a wider range of temperatures. As time goes on, in the 1800s, we can see that most of the purple hues are gone from the cities, leaving mostly greenish tones in the northern cities and cities further away from the equator; while the southern cities and the cities around the equator stayed consistently yellow. This pattern also persisted beyond the 1800s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGOSacM3Hso1"
      },
      "source": [
        "## 3.6 EDA in Global Land Temperatures by Major City Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31JwySzxyc-n"
      },
      "source": [
        "Let's now focus on the major cities and see how much they contribute to the climate trend.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQcQVS_4XWky"
      },
      "source": [
        "### 3.6.1 Average Temperature Plot for Major Cities on a World Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBDZeyt-0KXn"
      },
      "source": [
        "Using the interactve map above, let's graph the major cities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Llisz65Hso2"
      },
      "outputs": [],
      "source": [
        "# Convert Latitude and Longitude to numerical values if they are in string format\n",
        "if global_temp_major_city_cleaned['Latitude'].dtype == 'object':\n",
        "    global_temp_major_city_cleaned['Latitude'] = global_temp_major_city_cleaned['Latitude'].str.extract('(\\d+\\.\\d+)').astype(float)\n",
        "\n",
        "if global_temp_major_city_cleaned['Longitude'].dtype == 'object':\n",
        "    global_temp_major_city_cleaned['Longitude'] = global_temp_major_city_cleaned['Longitude'].str.extract('(\\d+\\.\\d+)').astype(float)\n",
        "\n",
        "# Group by Latitude and Longitude and calculate the average temperature\n",
        "average_temp_df = global_temp_major_city_cleaned.groupby(['Latitude', 'Longitude']).agg({\n",
        "    'City': 'first',\n",
        "    'AverageTemperature': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Normalize 'AverageTemperature' for sizing points on the plot\n",
        "min_temp = average_temp_df['AverageTemperature'].min()\n",
        "max_temp = average_temp_df['AverageTemperature'].max()\n",
        "average_temp_df['NormalizedTemperature'] = (average_temp_df['AverageTemperature'] - min_temp) / (max_temp - min_temp)\n",
        "\n",
        "# Manually set center and zoom level for the desired region\n",
        "center_lat = 30  # Center latitude\n",
        "center_lon = 0  # Center longitude\n",
        "zoom = 2  # Zoom level\n",
        "\n",
        "# Create an interactive map using plotly express\n",
        "fig = px.scatter_geo(\n",
        "    average_temp_df,\n",
        "    lat='Latitude',\n",
        "    lon='Longitude',\n",
        "    text='City',\n",
        "    size='NormalizedTemperature', # 'AverageTemperature' has been normalized to size the plot points, with larger points representing higher temperatures relative to the dataset's range\n",
        "    color='AverageTemperature',\n",
        "    color_continuous_scale='Viridis',\n",
        "    projection='natural earth',\n",
        "    title='Average Temperature Map',\n",
        "    size_max=15\n",
        ")\n",
        "\n",
        "# Add hover information\n",
        "fig.update_traces(hovertemplate='<b>%{text}</b><br>Temperature: %{marker.color:.2f}C')\n",
        "fig.update_layout(\n",
        "    geo=dict(\n",
        "        showcoastlines=True,\n",
        "        coastlinecolor=\"black\",\n",
        "        center=dict(lat=center_lat, lon=center_lon),\n",
        "        projection_scale=zoom,\n",
        "    ),\n",
        "    font=dict(size=8),  # Smaller font size for city names\n",
        "    geo_bgcolor=\"white\",  # Change background color\n",
        "    title=dict(font=dict(size=20)),  # Larger title font size\n",
        "    margin=dict(l=0, r=0, b=0, t=40),  # Adjust margin for better use of space\n",
        "    height=800,  # Set the height of the map\n",
        "    width=1200,  # Set the width of the map\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQxj7SUA1tDt"
      },
      "source": [
        "Like the cities data above, major cities that are further away from the equator have a lower average temperature. The size of the plot points is porportional to the temperature range, with larger points representing higher temperatures relative to the dataset's range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTAeqzjfl5Sd"
      },
      "source": [
        "### 3.6.2 Time-Series Temperature Interactive Map for Major Cities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLhuiJdW15Jx"
      },
      "source": [
        "Let's see how temperature changes over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhE2ua5El_AU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Assuming your DataFrame is named global_temp_city_cleaned\n",
        "# If not, replace global_temp_city_cleaned with your actual DataFrame name\n",
        "\n",
        "# Convert 'dt' to datetime format\n",
        "global_temp_major_city_cleaned['dt'] = pd.to_datetime(global_temp_major_city_cleaned['dt'], errors='coerce')\n",
        "\n",
        "# Convert Latitude and Longitude to numerical values if they are in string format\n",
        "global_temp_major_city_cleaned['Latitude'] = pd.to_numeric(global_temp_major_city_cleaned['Latitude'], errors='coerce')\n",
        "global_temp_major_city_cleaned['Longitude'] = pd.to_numeric(global_temp_major_city_cleaned['Longitude'], errors='coerce')\n",
        "\n",
        "# Group by Latitude, Longitude, and the nearest 10-year interval, and calculate the average temperature\n",
        "global_temp_major_city_cleaned['Year'] = (global_temp_major_city_cleaned['dt'].dt.year // 10) * 10\n",
        "average_temp_df = global_temp_major_city_cleaned.groupby(['Latitude', 'Longitude', 'Year']).agg({\n",
        "    'City': 'first',\n",
        "    'AverageTemperature': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Sort the DataFrame by 'Year' for correct animation order\n",
        "average_temp_df = average_temp_df.sort_values('Year')\n",
        "\n",
        "# Normalize 'AverageTemperature' for sizing points on the plot\n",
        "min_temp = average_temp_df['AverageTemperature'].min()\n",
        "max_temp = average_temp_df['AverageTemperature'].max()\n",
        "average_temp_df['NormalizedTemperature'] = (average_temp_df['AverageTemperature'] - min_temp) / (max_temp - min_temp)\n",
        "\n",
        "# Manually set center and zoom level for the desired region\n",
        "center_lat = 30  # Center latitude\n",
        "center_lon = 0  # Center longitude\n",
        "zoom = 2  # Zoom level\n",
        "\n",
        "# Create an interactive map using plotly express\n",
        "fig = px.scatter_geo(\n",
        "    average_temp_df,\n",
        "    lat='Latitude',\n",
        "    lon='Longitude',\n",
        "    text='City',\n",
        "    size='NormalizedTemperature',  # Use normalized temperature for sizing\n",
        "    color='AverageTemperature',\n",
        "    color_continuous_scale='Viridis',\n",
        "    animation_frame='Year',  # Add animation frame for the slider\n",
        "    projection='natural earth',\n",
        "    title='Average Temperature Map',\n",
        "    size_max=15  # Smaller dot sizes\n",
        ")\n",
        "\n",
        "# Add hover information\n",
        "fig.update_traces(hovertemplate='<b>%{text}</b><br>Temperature: %{marker.color:.2f}C')\n",
        "\n",
        "# Customize layout for readability\n",
        "fig.update_layout(\n",
        "    geo=dict(\n",
        "        showcoastlines=True,\n",
        "        coastlinecolor=\"black\",\n",
        "        center=dict(lat=center_lat, lon=center_lon),\n",
        "        projection_scale=zoom,\n",
        "    ),\n",
        "    font=dict(size=8),  # Smaller font size for city names\n",
        "    geo_bgcolor=\"white\",  # Change background color\n",
        "    title=dict(font=dict(size=20)),  # Larger title font size\n",
        "    margin=dict(l=0, r=0, b=0, t=40),  # Adjust margin for better use of space\n",
        "    height=800,  # Set the height of the map\n",
        "    width=1200,  # Set the width of the map\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ka8Zl80ul-"
      },
      "source": [
        "After all the major cities data points have been added in the mid 1800s, the average temperature from then on has not changed much, indicated by the lack of changes in the size and color of the plot points."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.7 Subset Guangzhou Data"
      ],
      "metadata": {
        "id": "xZV1LnJuEzYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For accuracy and simplicity, we choose to only analyze one major city."
      ],
      "metadata": {
        "id": "C6Co_CRHE5Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Guangzhou data from global_temp_major_city_cleaned\n",
        "gz = global_temp_major_city_cleaned[global_temp_major_city_cleaned['City'] == 'Guangzhou'].reset_index(drop=True)\n",
        "\n",
        "# Remove nulls\n",
        "gz = gz[gz.AverageTemperature.notnull()]\n",
        "\n",
        "# Sort by date\n",
        "gz = gz.sort_values(by='dt')"
      ],
      "metadata": {
        "id": "2VKOjz70E2xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QxJQuTkHso2"
      },
      "source": [
        "# Part 4: Feature Engineering & Preprocessing\n",
        "\n",
        "From our EDA, we see that a lot of data and relationships are being repeated among the datasets. To maintain comprehensive analysis, without repeating unnecessary information, we will focus our modeling on the following datasets:\n",
        "\n",
        "1.   Global Land Temperature: To understand the relationship between time and land temperature.\n",
        "2.   Global Land and Ocean Temperature: To understand the relationship between time and land/ocean temperature. Specifically, we're interested in learning more about this data because studies have shown that ocean temperatures are good predictors for the rise of future land temperatures.\n",
        "3.   Global Land Temperatures By City: To understand the relationship between latitude and land temperatures.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEJsQdKEHso2"
      },
      "source": [
        "## 4.1 Correlation Matrix for Global Land Temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDgyPy6THso2"
      },
      "outputs": [],
      "source": [
        "correlation_matrix_1 = global_temp_land_cleaned_modeling.corr()\n",
        "sns.heatmap(correlation_matrix_1, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCgGWdK3uank"
      },
      "source": [
        "From the correlation matrix, we see that there exists a relatively weak correlation between year and LandAverageTemperature. Because our dataset revolves around measuring long-term effects of gradual, small temperature changes, we will employ correlation significance testing via a Pearson Correlation Significance Test to further investigate this correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kDCBwd8uRow"
      },
      "outputs": [],
      "source": [
        "# Assuming 'time' and 'land_temperature' are your variables of interest\n",
        "time = global_temp_land_cleaned_modeling['year']\n",
        "land_temperature = global_temp_land_cleaned_modeling['LandAverageTemperature']\n",
        "\n",
        "# Calculate Pearson correlation coefficient and p-value\n",
        "correlation_coefficient, p_value = pearsonr(time, land_temperature)\n",
        "\n",
        "print(f\"Pearson Correlation Coefficient: {correlation_coefficient}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Check if the correlation is statistically significant\n",
        "alpha = 0.05  # Set your significance level\n",
        "if p_value < alpha:\n",
        "    print(\"The correlation is statistically significant.\")\n",
        "else:\n",
        "    print(\"The correlation is not statistically significant.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbxmZbvzvL2K"
      },
      "source": [
        "We see that the correlation is statistically significant, and because we are dealing with time-series data, we will explore time-based features and time-dependent trends in our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7ui4rOkm4XR"
      },
      "source": [
        "## 4.2 Correlation Matrix for Global Land and Ocean Temperatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRreNcP8mhI3"
      },
      "outputs": [],
      "source": [
        "cols_to_drop = ['LandMaxTemperature', 'LandMaxTemperatureUncertainty', 'LandMinTemperature', 'LandMinTemperatureUncertainty']\n",
        "global_temp_land_and_ocean_cleaned_modeling.drop(cols_to_drop, axis=1, inplace=True)\n",
        "global_temp_land_and_ocean_cleaned_modeling['year'] = pd.to_datetime(global_temp_land_and_ocean_cleaned_modeling['dt']).dt.year\n",
        "correlation_matrix_2 = global_temp_land_and_ocean_cleaned_modeling.corr()\n",
        "sns.heatmap(correlation_matrix_2, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6k771K-vcIK"
      },
      "source": [
        "Similar to above, from the correlation matrix, we see that there exists a correlation between year and temperature. However, this seems to be a very strong correlation between LandAndOceanAverageTemperature and year. We will employ correlation significance testing via a Pearson Correlation Significance Test to further investigate this correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itjLcUeQw0ov"
      },
      "outputs": [],
      "source": [
        "# Assuming 'time' and 'land_temperature' are your variables of interest\n",
        "time = global_temp_land_and_ocean_cleaned_modeling['year']\n",
        "land_and_ocean_temperature = global_temp_land_and_ocean_cleaned_modeling['LandAndOceanAverageTemperature']\n",
        "\n",
        "# Calculate Pearson correlation coefficient and p-value\n",
        "correlation_coefficient, p_value = pearsonr(time, land_and_ocean_temperature)\n",
        "\n",
        "print(f\"Pearson Correlation Coefficient: {correlation_coefficient}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Check if the correlation is statistically significant\n",
        "alpha = 0.05  # Set your significance level\n",
        "if p_value < alpha:\n",
        "    print(\"The correlation is statistically significant.\")\n",
        "else:\n",
        "    print(\"The correlation is not statistically significant.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qp9C1Mpw_ew"
      },
      "source": [
        "We see that the correlation is statistically significant, and because we are dealing with time-series data, we will explore time-based features and time-dependent trends in our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8xt3po9nWLy"
      },
      "source": [
        "## 4.3 Correlation Matrix for Global Land Temperatures by City Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwBIrDYRncmq"
      },
      "outputs": [],
      "source": [
        "correlation_matrix_3 = global_temp_city_cleaned_modeling.corr()\n",
        "sns.heatmap(correlation_matrix_3, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3DHpz7Px4pm"
      },
      "source": [
        "From the above correlation matrix, we see that there is a negative correlation between Latitude and AverageTemperature. This means that as latitude increases, temperature appears to decrease.\n",
        "\n",
        "This aligns with the well-known observation that temperatures tend to be colder at higher latitudes, especially towards the poles. The Earth's axial tilt and the way sunlight hits different latitudes contribute to this pattern."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Rolling Average and Plots"
      ],
      "metadata": {
        "id": "nc5792kvFCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the EDA portion, we will calculate and add a column for 10 years rolling average for better visualization.\n",
        "\n"
      ],
      "metadata": {
        "id": "SJTIkwG3FFLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate 10_year_rolling_avg\n",
        "gz['10_year_rolling_avg'] = gz['AverageTemperature'].rolling(window=120).mean()\n",
        "\n",
        "# Plot monthly average temperature and 10-year rolling average\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(gz['dt'], gz['AverageTemperature'], label='Monthly Average Temperature', alpha=0.5)\n",
        "plt.plot(gz['dt'], gz['10_year_rolling_avg'], label='10-Year Rolling Average', color='red', linewidth=2)\n",
        "plt.title('Guangzhou Average Temperature Over Time with 10 Years Rolling Average')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature (C)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q8CKBQaOFGFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average temperature over time graph has a slight upward trend, but it is not obvious. Let's graph the change in average temperature over time."
      ],
      "metadata": {
        "id": "3dLBGXDMFJF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph Guangzhou data\n",
        "mean_temp = gz[\"AverageTemperature\"].mean()\n",
        "gz[\"AverageTemperatureDelta\"] = gz[\"AverageTemperature\"] - mean_temp\n",
        "\n",
        "fig_dims = (10, 8)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "avg_temp = gz.groupby(gz['dt'].dt.year).mean()\n",
        "avg_temp[\"AverageTemperatureDelta\"].plot(linewidth=1, label ='delta T')\n",
        "plt.axhline(y=0, color='r', linestyle='-', label = 'average')\n",
        "plt.title('Guangzhou temperature', fontsize=20)\n",
        "plt.xlabel('year', fontsize=15)\n",
        "plt.ylabel('C', fontsize=15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "-mC8pC_eFHbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, Guangzhou's average temperature has an upward trend over time. Let's plot the difference between the annual temperature with the mean temperature."
      ],
      "metadata": {
        "id": "Lp32mEfaFM4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the difference with respect the mean temperature\n",
        "\n",
        "fig_dims = (20, 14)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "avg_temp[\"AverageTemperatureDelta\"].plot.bar(linewidth=1, label ='delta T')\n",
        "plt.axhline(y=0, color='r', linestyle='-', label = 'average')\n",
        "plt.title('Change in Guangzhou temperature ', fontsize=20)\n",
        "plt.legend(fontsize='x-large')\n",
        "\n",
        "# Show only some xticks\n",
        "for i, t in enumerate(ax.get_xticklabels()):\n",
        "    if (i % 5) != 0:\n",
        "        t.set_visible(False)\n",
        "plt.xlabel('Year', fontsize=15)\n",
        "plt.ylabel('C', fontsize=15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "AV8Tal_TFNRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot is just another way of showing the line graph above: temperature has been increasing over time because of the positive differnce in later years with respect to the mean temperature."
      ],
      "metadata": {
        "id": "qjpvd2wcFQWn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnAJwuIqHso2"
      },
      "source": [
        "# Part 5: Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WILN4Tft7Ioz"
      },
      "source": [
        "## 5.1 Linear Regression (Supervised Learning Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPHr0UrqzHA8"
      },
      "source": [
        "### 5.1.1 Using Data Pre-1950s to Predict Post-1950s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zSq4otPz5eU"
      },
      "source": [
        "To predict future temperatures, we will employ a Linear Regression Model. Specifically, during our EDA, we saw that AverageTemperature seemed to follow a linear trend over time. Thus, linear regression can be useful because we want to capture a linear trend in the time-series data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UFF2inLz2ov"
      },
      "outputs": [],
      "source": [
        "# Get average temperature by year\n",
        "average_temperature_by_year = global_temp_land_cleaned_modeling.groupby('year')['LandAverageTemperature'].mean().reset_index()\n",
        "\n",
        "# Calculate Pearson correlation\n",
        "year = average_temperature_by_year['year']\n",
        "temperature = average_temperature_by_year['LandAverageTemperature']\n",
        "corr, p = pearsonr(year, temperature)\n",
        "print('Pearson correlation of Year and Land Average Temperature: {:.2f}'.format(corr))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a specific time point for the split (e.g., 80% for training, 20% for testing)\n",
        "split_date = average_temperature_by_year['year'].iloc[int(0.8 * len(average_temperature_by_year))]\n",
        "\n",
        "# Split the data into training and testing sets based on the time point\n",
        "train = average_temperature_by_year[average_temperature_by_year['year'] < split_date]\n",
        "test = average_temperature_by_year[average_temperature_by_year['year'] >= split_date]\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X_train = train[['year']]\n",
        "y_train = train['LandAverageTemperature']\n",
        "X_test = test[['year']]\n",
        "y_test = test['LandAverageTemperature']\n",
        "\n",
        "lr = LinearRegression()\n",
        "\n",
        "X = year\n",
        "y = temperature\n",
        "\n",
        "X = X.values.reshape(-1,1)\n",
        "\n",
        "lr.fit(X, y)\n",
        "\n",
        "y_pred = lr.predict(X)\n",
        "\n",
        "years = pd.DataFrame(X)\n",
        "\n",
        "plt.figure(figsize=(18,10))\n",
        "plt.scatter(X, y, alpha=0.6)\n",
        "plt.plot(X, y_pred, color=\"orange\")\n",
        "plt.xlabel('Years')\n",
        "plt.ylabel('Temperature (in C)')\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "PxUiblL1wcyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.coef_)\n",
        "print(10 * lr.coef_)"
      ],
      "metadata": {
        "id": "pTHRwQYfwe9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every year, the average land temperature increases by an average of 0.0047 C. Every ten years, the average land temperature increases by an average of 0.0473 C."
      ],
      "metadata": {
        "id": "LqTjFQUJ37Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract years from 2015 to 2050\n",
        "future_years = np.arange(2015, 2051, 1).reshape(-1, 1)\n",
        "\n",
        "# Filter data for years 2015 and onwards\n",
        "recent_years_data = average_temperature_by_year[average_temperature_by_year['year'] > 2015]\n",
        "\n",
        "# Use the linear regression model to predict temperatures for future years\n",
        "future_predictions = lr.predict(future_years)\n",
        "\n",
        "# Plot the original data and the linear regression predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(recent_years_data['year'], recent_years_data['LandAverageTemperature'], label='_nolegend_', marker='o')\n",
        "plt.plot(future_years, future_predictions, label='Linear Regression Predictions', color='red')\n",
        "plt.title('Linear Regression Predictions of Land Average Temperature Through 2050')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Land Average Temperature')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_I1FRIUgwi8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.predict(np.array([2030, 2040, 2050]).reshape(-1,1)))"
      ],
      "metadata": {
        "id": "TuyiazCRwmFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation** The average land temperature in 2030 will be 9.067 C, 2040 9.115 C, 2050 9.162 C."
      ],
      "metadata": {
        "id": "jusApP4-3-Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.1.2 1950 - 2015 Data on Global Average Temperatures\n",
        "Historically, land temperatures have risen at more significant rates following industrialization and World War II (post 1950s). So, using past temperature data from before the 1950s to measure temperatures post-industrialization is likely misrepresentative."
      ],
      "metadata": {
        "id": "iIznk4OewqyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for years 1950 and onwards\n",
        "recent_years_data = average_temperature_by_year[average_temperature_by_year['year'] >= 1950]\n",
        "\n",
        "# Calculate Pearson correlation for years 1950 and onwards\n",
        "corr, p = pearsonr(recent_years_data['year'], recent_years_data['LandAverageTemperature'])\n",
        "print('Pearson correlation of Year and Land Average Temperature (1950 and onwards): {:.2f}'.format(corr))"
      ],
      "metadata": {
        "id": "QaMHdKeKwvut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation** We can see a very strong positive correlation"
      ],
      "metadata": {
        "id": "8UeP06s1wyMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for years post-1950\n",
        "post_1950_data = average_temperature_by_year[average_temperature_by_year['year'] > 1950]\n",
        "\n",
        "# Linear Regression\n",
        "lr = LinearRegression()\n",
        "\n",
        "X = post_1950_data['year'].values.reshape(-1, 1)\n",
        "y = post_1950_data['LandAverageTemperature']\n",
        "\n",
        "lr.fit(X, y)\n",
        "\n",
        "y_pred = lr.predict(X)\n",
        "\n",
        "# Plot the scatter plot and linear regression line\n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.scatter(X, y, alpha=0.6)\n",
        "plt.plot(X, y_pred, color=\"orange\", label='Linear Regression Line')\n",
        "plt.xlabel('Years')\n",
        "plt.ylabel('Temperature (in C)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "Givo1aAgwzRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.coef_)\n",
        "print(10 * lr.coef_)"
      ],
      "metadata": {
        "id": "6a9R16Pgw177"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**\n",
        "Every year, the average land temperature increases by an average of 0.0185 C. Every ten years, the average land temperature increases by an average of 0.1852 C."
      ],
      "metadata": {
        "id": "cy1Bk_I7w4Fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract years from 2015 to 2050\n",
        "future_years = np.arange(2015, 2051, 1).reshape(-1, 1)\n",
        "\n",
        "# Filter data for years 2015 and onwards\n",
        "recent_years_data = average_temperature_by_year[average_temperature_by_year['year'] > 2015]\n",
        "\n",
        "# Use the linear regression model to predict temperatures for future years\n",
        "future_predictions = lr.predict(future_years)\n",
        "\n",
        "# Plot the original data and the linear regression predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(recent_years_data['year'], recent_years_data['LandAverageTemperature'], label='_nolegend_', marker='o')\n",
        "plt.plot(future_years, future_predictions, label='Linear Regression Predictions', color='red')\n",
        "plt.title('Linear Regression Predictions of Land Average Temperature Through 2050')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Land Average Temperature')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5A51I5Xew5qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.predict(np.array([2030, 2040, 2050]).reshape(-1,1)))"
      ],
      "metadata": {
        "id": "gQxZiWm4w7i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**\n",
        "The average land temperature in 2030 will be 9.856 C, 2040 10.041 C, 2050 10.226 C.\n",
        "\n"
      ],
      "metadata": {
        "id": "cgmz909Vw96e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1MGfLde-H4P"
      },
      "source": [
        "## 5.2 XGBoost (Supervised Learning Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rryV4lp-YBY"
      },
      "source": [
        "Gradient boosting algorithms like XGBoost build trees sequentially, each one correcting the errors of the previous ones. Specificaly, XGBoost is capable of capturing non-linear relationships in the data. Temperature data often exhibits complex patterns that may not be well-modeled by linear regression alone. XGBoost, with its ability to build ensembles of decision trees, can capture intricate non-linear relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RhkhZui_Axf"
      },
      "source": [
        "### 5.2.1 Using Data Pre-1950s to Predict Post-1950s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjiS-VTj-pfk"
      },
      "outputs": [],
      "source": [
        "# Adapt the date_transform function\n",
        "def date_transform(data):\n",
        "    df = data.copy()\n",
        "\n",
        "    # Extract various date-related features from the datetime index\n",
        "    df['Month'] = df['dt'].dt.month\n",
        "    df['Quarter'] = df['dt'].dt.quarter\n",
        "    df['Year'] = df['dt'].dt.year\n",
        "\n",
        "    # Keep only the needed columns for training and prediction\n",
        "    X = df[['Month', 'Quarter', 'Year']]\n",
        "    y = df['LandAverageTemperature']\n",
        "    return X, y\n",
        "\n",
        "# Sort the data by time\n",
        "global_temp_land_cleaned_modeling = global_temp_land_cleaned_modeling.sort_values(by='dt')\n",
        "\n",
        "# Set a specific time point for the split (e.g., 80% for training, 20% for testing)\n",
        "split_date = global_temp_land_cleaned_modeling['dt'].iloc[int(0.8 * len(global_temp_land_cleaned_modeling))]\n",
        "\n",
        "# Split the data into training and testing sets based on the time point\n",
        "train = global_temp_land_cleaned_modeling[global_temp_land_cleaned_modeling['dt'] < split_date]\n",
        "test = global_temp_land_cleaned_modeling[global_temp_land_cleaned_modeling['dt'] >= split_date]\n",
        "\n",
        "# Apply date_transform to the training set\n",
        "X_train, y_train = date_transform(train)\n",
        "\n",
        "# Apply date_transform to the testing set\n",
        "X_test, y_test = date_transform(test)\n",
        "\n",
        "# Train an XGBoost model\n",
        "xgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, early_stopping_rounds=10)\n",
        "xgb_model.fit(X_train, y_train, eval_metric='mae', eval_set=[(X_train, y_train), (X_test, y_test)])\n",
        "\n",
        "# Make predictions on the testing set\n",
        "xgb_pred = xgb_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Absolute Error (MAE)\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = round(mean_absolute_error(y_test, xgb_pred), 3)\n",
        "print(mae)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, xgb_pred)\n",
        "r2 = r2_score(y_test, xgb_pred)\n",
        "print(mse)\n",
        "print(r2)"
      ],
      "metadata": {
        "id": "RvSq7wTRxiH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.dates as mdates\n",
        "# Create a DataFrame for plotting\n",
        "df_plot = pd.DataFrame({'y_test': y_test.values, 'xgb_pred': xgb_pred}, index=test['dt'])\n",
        "\n",
        "# Plot the actual vs. predicted results\n",
        "plt.figure(figsize=(20, 8))\n",
        "df_plot['y_test'].plot(label='Actual')\n",
        "df_plot['xgb_pred'].plot(label='Predicted')\n",
        "\n",
        "# Add axis labels\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Land Average Temperature')\n",
        "\n",
        "#Add title and legend\n",
        "plt.title('Testing Set Forecast', weight='bold', fontsize=20)\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IlYTRBE2xjCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-e4NBxm_LpG"
      },
      "source": [
        "From the results, we see that the MSE is relatively unchanged from the Error produced by the Linear Regression Model. The R-squared value, while still negative, has significantly decreased in magnitude."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpFizhXUApVN"
      },
      "source": [
        "### 5.2.2 Using data Post-1950s to Predict Post-2000s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbujbfesAtfI"
      },
      "outputs": [],
      "source": [
        "# Adapt the date_transform function\n",
        "def date_transform(data):\n",
        "    df = data.copy()\n",
        "\n",
        "    # Extract various date-related features from the datetime index\n",
        "    df['Month'] = df['dt'].dt.month\n",
        "    df['Quarter'] = df['dt'].dt.quarter\n",
        "    df['Year'] = df['dt'].dt.year\n",
        "\n",
        "    # Keep only the needed columns for training and prediction\n",
        "    X = df[['Month', 'Quarter', 'Year']]\n",
        "    y = df['LandAverageTemperature']\n",
        "    return X, y\n",
        "\n",
        "# Filter data from January 1, 1950, and beyond\n",
        "global_temp_land_cleaned_modeling_post_1950 = global_temp_land_cleaned_modeling[global_temp_land_cleaned_modeling['dt'] >= '1950-01-01']\n",
        "\n",
        "# Sort the data by time\n",
        "global_temp_land_cleaned_modeling_post_1950 = global_temp_land_cleaned_modeling_post_1950.sort_values(by='dt')\n",
        "\n",
        "# Set a specific time point for the split (e.g., 80% for training, 20% for testing)\n",
        "split_date = global_temp_land_cleaned_modeling_post_1950['dt'].iloc[int(0.8 * len(global_temp_land_cleaned_modeling_post_1950))]\n",
        "\n",
        "# Split the data into training and testing sets based on the time point\n",
        "train = global_temp_land_cleaned_modeling_post_1950[global_temp_land_cleaned_modeling_post_1950['dt'] < split_date]\n",
        "test = global_temp_land_cleaned_modeling_post_1950[global_temp_land_cleaned_modeling_post_1950['dt'] >= split_date]\n",
        "\n",
        "# Apply date_transform to the training set\n",
        "X_train, y_train = date_transform(train)\n",
        "\n",
        "# Apply date_transform to the testing set\n",
        "X_test, y_test = date_transform(test)\n",
        "print(X_train.tail)\n",
        "print(y_train.tail)\n",
        "\n",
        "# Train an XGBoost model\n",
        "xgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, early_stopping_rounds=10)\n",
        "xgb_model.fit(X_train, y_train, eval_metric='mae', eval_set=[(X_train, y_train), (X_test, y_test)])\n",
        "\n",
        "# Make predictions on the testing set\n",
        "xgb_pred = xgb_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Absolute Error (MAE)\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mae = round(mean_absolute_error(y_test, xgb_pred), 3)\n",
        "print(mae)\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, xgb_pred)\n",
        "r2 = r2_score(y_test, xgb_pred)\n",
        "print(mse)\n",
        "print(r2)"
      ],
      "metadata": {
        "id": "Lx3hed2-yCgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.dates as mdates\n",
        "# Create a DataFrame for plotting\n",
        "df_plot = pd.DataFrame({'y_test': y_test.values, 'xgb_pred': xgb_pred}, index=test['dt'])\n",
        "\n",
        "# Plot the actual vs. predicted results\n",
        "plt.figure(figsize=(20, 8))\n",
        "df_plot['y_test'].plot(label='Actual')\n",
        "df_plot['xgb_pred'].plot(label='Predicted')\n",
        "\n",
        "# Add axis labels\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Land Average Temperature')\n",
        "\n",
        "#Add title and legend\n",
        "plt.title('Testing Set Forecast', weight='bold', fontsize=20)\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VBVu92LHyEwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA_3B1zMLyFf"
      },
      "source": [
        "### 5.3.3 Using Hyper-Parameter Tuning on XGBoost\n",
        "We chose to do hyperparemeter search on data post-1950"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEm4uYUrL5Mg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "}\n",
        "\n",
        "# Adapt the date_transform function\n",
        "def date_transform(data):\n",
        "    df = data.copy()\n",
        "\n",
        "    # Extract various date-related features from the datetime index\n",
        "    df['Month'] = df['dt'].dt.month\n",
        "    df['Quarter'] = df['dt'].dt.quarter\n",
        "    df['Year'] = df['dt'].dt.year\n",
        "\n",
        "    # Keep only the needed columns for training and prediction\n",
        "    X = df[['Month', 'Quarter', 'Year']]\n",
        "    y = df['LandAverageTemperature']\n",
        "    return X, y\n",
        "# Filter data for dates post-1950\n",
        "filtered_data = global_temp_land_cleaned_modeling[global_temp_land_cleaned_modeling['dt'] >= '1950-01-01']\n",
        "\n",
        "# Set a specific time point for the split (e.g., 80% for training, 20% for testing)\n",
        "split_date = filtered_data['dt'].iloc[int(0.8 * len(filtered_data))]\n",
        "\n",
        "# Split the data into training and testing sets based on the time point\n",
        "train = filtered_data[filtered_data['dt'] < split_date]\n",
        "test = filtered_data[filtered_data['dt'] >= split_date]\n",
        "\n",
        "# Apply date_transform to the training set\n",
        "X_train, y_train = date_transform(train)\n",
        "\n",
        "# Apply date_transform to the testing set\n",
        "X_test, y_test = date_transform(test)\n",
        "\n",
        "# Create an XGBoost model\n",
        "xgb_model = XGBRegressor()\n",
        "\n",
        "# Set up the grid search with cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_squared_error',  # Choose an appropriate scoring metric\n",
        "    cv=TimeSeriesSplit(n_splits=5),  # Time series cross-validation\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Perform the grid search on the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print Best Parameters and Best Score\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "print(\"Best Score: \", grid_search.best_score_)\n",
        "print(\"Lowest MSE found: \", -grid_search.best_score_)\n",
        "\n",
        "\n",
        "# Get the Best Model\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Make Predictions on the Test Set\n",
        "y_pred_test = best_xgb_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOaKfxSKNhJp"
      },
      "outputs": [],
      "source": [
        "# Add the predicted values to the test DataFrame\n",
        "test['LandAverageTemperature_Pred'] = y_pred\n",
        "\n",
        "# Extract year from the 'dt' column\n",
        "test['year'] = test['dt'].dt.year\n",
        "\n",
        "# Evaluate the Model on Test Set\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "print(\"Mean Squared Error on Test Set: \", mse_test)\n",
        "\n",
        "# Plot Actual vs. Predicted on Test Set\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(X_test.index, y_test, label='Actual')\n",
        "plt.plot(X_test.index, y_pred_test, label='Predicted', linestyle='--')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Land Average Temperature')\n",
        "plt.title('Actual vs. Predicted on Test Set')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_2WsY2RDRGY"
      },
      "source": [
        "## 5.3 SARIMA Model for Guangzhou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twbpEhLFh-k8"
      },
      "source": [
        "ARIMA is a common time-series forecasting model used only on stationary data, and SARIMA is used on data that display seasonality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGjU99_OiKv9"
      },
      "source": [
        "### 5.3.1 Stationarity Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVa49JnaiHRA"
      },
      "outputs": [],
      "source": [
        "print(\"The p-value for the ADF test in Guangzhou is \", adfuller(gz['AverageTemperature'])[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-D_M4hYi_83"
      },
      "source": [
        "The p-value is less than alpha, 0.05, so we reject the null hypothesis. The New York City temperature data is stationary, so we can move onto ARIMA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAqMNDoP6zmg"
      },
      "source": [
        "### 5.3.2 Autocorrelation Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgVgHkzV64AR"
      },
      "outputs": [],
      "source": [
        "plot_acf(gz['AverageTemperature'], lags=20)\n",
        "plt.show()\n",
        "\n",
        "plot_pacf(gz['AverageTemperature'], lags=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sncoOw-xq_G8"
      },
      "source": [
        "The plots above showed seasonality, so we should use SARIMAX instead, which takes care of seasonal data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceMYxA2UD6Q6"
      },
      "source": [
        "### 5.3.3 Run Model and Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zsYdvZI-YBX"
      },
      "outputs": [],
      "source": [
        "# Run auto_arima to find the best combination of p,d,q for SARMIAX\n",
        "# Note that this portion takes a lot of computational resources\n",
        "model = auto_arima(gz['AverageTemperature'],\n",
        "                       start_p=1,\n",
        "                       start_q=1,\n",
        "                       max_p=3,\n",
        "                       max_q=3,\n",
        "                       start_P=1,\n",
        "                       start_Q=1,\n",
        "                       max_P=2,\n",
        "                       max_Q=2,\n",
        "                       m=12,\n",
        "                       seasonal=True,\n",
        "                       d=1,\n",
        "                       D=1,\n",
        "                       trend = 'ct',\n",
        "                       test = 'adf',\n",
        "                       trace=True,\n",
        "                       error_action='ignore',\n",
        "                       suppress_warnings=True,\n",
        "                       stepwise=True)\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh07bnVMnnCR"
      },
      "outputs": [],
      "source": [
        "model = SARIMAX(gz['AverageTemperature'],\n",
        "                order=(1, 1, 1),\n",
        "                seasonal_order=(1, 1, 1, 12),\n",
        "                enforce_stationarity=False,\n",
        "                enforce_invertibility=False)\n",
        "\n",
        "# Fit the model\n",
        "model_fit = model.fit(disp=False)\n",
        "\n",
        "# Forecast the next 40 years (480 months)\n",
        "forecast = model_fit.get_forecast(steps=480)\n",
        "\n",
        "# Get the forecast mean\n",
        "forecast_mean = forecast.predicted_mean.reset_index()\n",
        "\n",
        "# Get the confidence intervals of the forecast\n",
        "forecast_ci = forecast.conf_int()\n",
        "\n",
        "# Prepare the data for plotting\n",
        "forecast_index = pd.date_range(gz.dt.iloc[-1], periods=481, freq='M')[1:]\n",
        "forecast_mean['index'] = forecast_index\n",
        "forecast_mean['LowerCI'] = forecast_ci.iloc[:, 0].tolist()\n",
        "forecast_mean['UpperCI'] = forecast_ci.iloc[:, 1].tolist()\n",
        "forecast_mean.rename(columns={'index': 'dt'}, inplace=True)\n",
        "forecast_mean['10_year_rolling_avg'] = forecast_mean['predicted_mean'].rolling(window=120).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_v643GtOqV-"
      },
      "outputs": [],
      "source": [
        "# Plot\n",
        "plt.figure(figsize=(22,10))\n",
        "plt.plot(gz.dt, gz['AverageTemperature'], label = \"Historical\")\n",
        "plt.plot(forecast_mean.dt, forecast_mean['predicted_mean'], label = \"Forecast Out of Sample\")\n",
        "plt.plot(gz.dt, gz['10_year_rolling_avg'], label='10-Year Rolling Average Historical', color='red', linewidth=2)\n",
        "plt.plot(forecast_mean.dt, forecast_mean['10_year_rolling_avg'], label='10-Year Rolling Average Forecast', color='green', linewidth=2)\n",
        "plt.title(\"Time Series Forecast\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Mean Temperature\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since Guangzhou's temperature stayed pretty constant over tume, SARIMA's forecasting result also reflects that: the average temperature 40 years into the future is also predicted to be constant."
      ],
      "metadata": {
        "id": "3qtVzDDypu57"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_CT6emX558c"
      },
      "source": [
        "## 5.4 SARIMA on Land and Ocean Temperatures Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwWZJ-Wn55uR"
      },
      "source": [
        "Let's also see how SARIMA works on the nonstationary land and ocean temperatures data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sTSS6hE57Kv"
      },
      "outputs": [],
      "source": [
        "# Bringing back graph from above\n",
        "# Calculate 10_year_rolling_avg\n",
        "global_temp_land_and_ocean_cleaned['10_year_rolling_avg_ocean'] = global_temp_land_and_ocean_cleaned['LandAndOceanAverageTemperature'].rolling(window=120).mean()\n",
        "\n",
        "# Plot monthly average temperature and 10-year rolling average\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(global_temp_land_and_ocean_cleaned['dt'], global_temp_land_and_ocean_cleaned['LandAndOceanAverageTemperature'], label='Monthly Average Temperature', alpha=0.5)\n",
        "plt.plot(global_temp_land_and_ocean_cleaned['dt'], global_temp_land_and_ocean_cleaned['10_year_rolling_avg_ocean'], label='10-Year Rolling Average', color='red', linewidth=2)\n",
        "plt.title('Land and Ocean Average Temperature Over Time with 10 Years Rolling Average')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature (C)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the data above for manipulation\n",
        "df = global_temp_land_and_ocean_cleaned.copy()\n",
        "meanTemp = df[\"LandAndOceanAverageTemperature\"].mean()\n",
        "df[\"LandAndOceanAverageTemperatureDelta\"] = df[\"LandAndOceanAverageTemperature\"] - meanTemp\n",
        "df['10_year_rolling_avg'] = df['LandAndOceanAverageTemperatureDelta'].rolling(window=120).mean()\n",
        "avgTemp = df.groupby(df['dt'].dt.year).mean()\n",
        "\n",
        "# Plot change in temperature graph with rolling average\n",
        "fig_dims = (10, 8)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "avgTemp[\"LandAndOceanAverageTemperatureDelta\"].plot(linewidth=1, label ='delta T')\n",
        "plt.axhline(y=0, color='r', linestyle='-', label = 'average')\n",
        "plt.title('Change in Land & Ocean temperature ', fontsize=20)\n",
        "plt.legend(fontsize='x-large')\n",
        "plt.xlabel('year', fontsize=15)\n",
        "plt.ylabel('C', fontsize=15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "poorYppyGff1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.1 Stationarity and Autcorrelations Check"
      ],
      "metadata": {
        "id": "BeMa35s3Grbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As analyzed in section 3.2, this data is not stationary and has seasonality, but SARIMAX addresses both of those issues."
      ],
      "metadata": {
        "id": "UbsdnWUuGt_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.2 Run Model and Get Predictions"
      ],
      "metadata": {
        "id": "uFRtAUB_Gv_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up SARIMA model\n",
        "model = SARIMAX(df['LandAndOceanAverageTemperatureDelta'], order=(0, 1, 3), seasonal_order=(1,1,[1, 2],12), trend='ct')\n",
        "model_fit = model.fit()\n",
        "print(model_fit.summary())"
      ],
      "metadata": {
        "id": "lFOzApU9GslW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We want to forecast temperature 40 years into the future\n",
        "nbStep = 12*40\n",
        "forecast = model_fit.get_forecast(steps=nbStep)\n",
        "\n",
        "forecast = forecast.summary_frame()\n",
        "\n",
        "forecasts = pd.DataFrame(columns = ['LandAndOceanAverageTemperaturePredictions','LandAndOceanAverageTemperaturePredictionsUpper','LandAndOceanAverageTemperaturePredictionsLower'])\n",
        "forecasts['LandAndOceanAverageTemperaturePredictions'] = forecast['mean']\n",
        "forecasts['LandAndOceanAverageTemperaturePredictionsUpper'] = forecast['mean_ci_upper']\n",
        "forecasts['LandAndOceanAverageTemperaturePredictionsLower'] = forecast['mean_ci_lower']\n",
        "forecasts['10_year_rolling_avg_forecast'] = forecasts['LandAndOceanAverageTemperaturePredictions'].rolling(window=120).mean()\n",
        "forecasts.index = forecast.index\n",
        "\n",
        "forecast_period = pd.date_range(start=df['dt'].iloc[-1], periods=nbStep+1, freq='M')[1:]\n",
        "forecasts['dt'] = forecast_period"
      ],
      "metadata": {
        "id": "IgPscPzCGyHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot forecasting temperature\n",
        "plt.figure(figsize=(22,10))\n",
        "plt.plot(df.dt, df['LandAndOceanAverageTemperatureDelta'],label = \"original\")\n",
        "plt.plot(forecasts.dt, forecasts['LandAndOceanAverageTemperaturePredictions'],label = \"forecast out of sample\")\n",
        "plt.plot(df.dt, df['10_year_rolling_avg'], label='10-Year Rolling Average Historical', color='red', linewidth=2)\n",
        "plt.plot(forecasts.dt, forecasts['10_year_rolling_avg_forecast'], label='10-Year Rolling Average Forecast', color='green', linewidth=2)\n",
        "plt.title(\"Land & Ocean Temperature Forecast\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Mean Temperature\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G_CTyHtVG6_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot temperature forecast with confidence intervals\n",
        "avgTemp = df.groupby(df['dt'].dt.year).mean()\n",
        "avgTempPred = forecasts.groupby(forecasts['dt'].dt.year).mean()\n",
        "fig_dims = (10, 8)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "avgTemp[\"LandAndOceanAverageTemperatureDelta\"].plot(linewidth=1, label='original')\n",
        "avgTempPred[\"LandAndOceanAverageTemperaturePredictions\"].plot(linewidth=1, label='forecast out of sample')\n",
        "ax.fill_between(avgTempPred.index, avgTempPred['LandAndOceanAverageTemperaturePredictionsLower'], avgTempPred['LandAndOceanAverageTemperaturePredictionsUpper'], color='k', alpha=0.1);\n",
        "plt.title('Land & Ocean Temperature Forecast with Confidence Intervals', fontsize=20)\n",
        "plt.xlabel('year', fontsize=15)\n",
        "plt.ylabel('C', fontsize=15)\n",
        "plt.legend(fontsize='x-large')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "dZ9jaPV8HBXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike Guangzhou's prediction, the forecasting result for this dataset has a clear upward trend, reaffirming our previous observations about global land and ocean temperature trend is going up."
      ],
      "metadata": {
        "id": "lVRTmkfaqb8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6: Summary"
      ],
      "metadata": {
        "id": "_WU7oVdU4W4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In conclusion, here are our main takeaways from this project:**\n",
        "\n",
        "1.\tTime series data come with unique challenges and characteristics that require careful preprocessing before applying any modeling technique, especially when the goal is forecasting future values\n",
        "2.\tAdditionally, forecasting needs to meet a lot of assumptions in order to implement specific models\n",
        "3.\tVisualizing the data can give insight as to what models we could build - for example since some data is non stationary, arima would not be a good choice for forecasting, instead we should opt for models that can tolerate nonstationarity and seasonality like SARIMA and Prophet\n",
        "4.\tUnlike typical machine learning problems, random train-test splits are not suitable for time series data. Instead, a chronological split is necessary to evaluate the model's performance on unseen future data.\n",
        "5.\tThe best model for forecasting was SARIMA and XGBoost demonstrated proficiency in capturing the underlying seasonal patterns within the dataset.\n",
        "6.\tThe global temperature trend has exhibited a pronounced upward slope since 1950, indicating a significant and concerning acceleration correlated with the rapid pace of industrialization and heightened emissions.\n",
        "\n",
        "**In the future, it would be interesting to consider implementing the following modifications:**\n",
        "1.\tImplement Neural Networks and using advanced architectures such as LSTM\n",
        "2.\tExperimenting with Prophet for additional forecasting potential\n",
        "3.\tSubsampling by season to see the trends throughout the years based on the time of year\n",
        "\n",
        "**Overall Experience + Team Reflection:**\n",
        "1.\tWe really enjoyed working on this project because it allowed us to apply the skills/tools we learned in class to a prevalent issues in todays world\n",
        "2.\tIt was especially fun working with and learning about the different packages for data visualization (we especially thought the interactive globe ones were pretty cool)\n",
        "3.\tHaving to constantly iterate to refine our models required a lot of time but it forced us to think critically and experiment with different parameters/models to see what performed best"
      ],
      "metadata": {
        "id": "pOWOUjrb4o58"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 29,
          "sourceId": 2150,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30579,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
